{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook outlines the steps involved in building and deploying a Battlesnake model using Ray RLlib and TensorFlow on Amazon SageMaker.\n",
    "\n",
    "Library versions currently in use:  TensorFlow 2.1, Ray RLlib 0.8.2\n",
    "\n",
    "The model is first trained using multi-agent PPO, and then deployed to a managed _TensorFlow Serving_ SageMaker endpoint that can be used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise sagemaker\n",
    "We need to define several parameters prior to running the training job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket path: s3://sagemaker-us-west-2-752200179490/\n"
     ]
    }
   ],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "s3_bucket = sm_session.default_bucket()\n",
    "\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::752200179490:role/service-role/AmazonSageMaker-ExecutionRole-20200224T083055\n"
     ]
    }
   ],
   "source": [
    "# job_name_prefix = 'Battlesnake-job-rllib-hete'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change local_mode to True if you want to do local training within this Notebook instance\n",
    "# Otherwise, we'll spin-up a SageMaker training instance to handle the training\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = 'local'\n",
    "else:\n",
    "    instance_type = \"SAGEMAKER_TRAINING_INSTANCE_TYPE\"\n",
    "    \n",
    "# If training locally, do some Docker housekeeping..\n",
    "if local_mode:\n",
    "    !/bin/bash ./common/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = sm_session.boto_region_name\n",
    "device = \"cpu\"\n",
    "cpu_image_name = '462105765813.dkr.ecr.{region}.amazonaws.com/sagemaker-rl-ray-container:ray-0.8.2-tf-{device}-py36'.format(region=region, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single instance, multiple core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define and execute our training job\n",
    "# Adjust hyperparameters and train_instance_count accordingly\n",
    "\n",
    "metric_definitions = RLEstimator.default_metric_definitions(RLToolkit.RAY) + [{'Name': 'episode_len_mean',\n",
    "  'Regex': 'episode_len_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, {'Name': 'episodes_total',\n",
    "  'Regex': 'episodes_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, {'Name': 'num_steps_trained',\n",
    "  'Regex': 'num_steps_trained: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, {'Name': 'training_iteration',\n",
    "  'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}]\n",
    "\n",
    "job_name_prefix = 'anna-1m5-singlenode'\n",
    "    \n",
    "estimator = RLEstimator(entry_point=\"train-mabs-dqn.py\",\n",
    "                        source_dir='training/training_src',\n",
    "                        dependencies=[\"training/common/sagemaker_rl\", \"../BattlesnakeGym/\"],\n",
    "                        image_name=cpu_image_name,\n",
    "                        role=role,\n",
    "                        train_instance_type=instance_type,\n",
    "                        train_instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        base_job_name=job_name_prefix,\n",
    "                        metric_definitions=metric_definitions,\n",
    "                        hyperparameters={\n",
    "                            # See train-mabs.py to add additional hyperparameters\n",
    "                            # Also see ray_launcher.py for the rl.training.* hyperparameters\n",
    "                            #\n",
    "                            # number of training iterations\n",
    "                            \"num_iters\": 5000,\n",
    "                            # number of snakes in the gym\n",
    "                            \"num_agents\": 5,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "estimator.fit(wait=False)\n",
    "\n",
    "job_name = estimator.latest_training_job.job_name\n",
    "print(\"Training job: %s\" % job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogeneous scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Training job: anna-homogenous-3m5-async-largebatch-2020-04-24-02-37-24-168\n"
     ]
    }
   ],
   "source": [
    "job_name_prefix = 'anna-homogenous-3m5-async-largebatch'\n",
    "\n",
    "train_instance_count = 3\n",
    "\n",
    "estimator = RLEstimator(entry_point=\"train-mabs-dqn-async.py\",\n",
    "                            source_dir='rllib_src',\n",
    "                            dependencies=[\"rllib_common/sagemaker_rl\", \"battlesnake_gym/\"],\n",
    "                            image_name=cpu_image_name, # gpu_image_name if we have\n",
    "                            role=role,\n",
    "                            train_instance_type=instance_type,\n",
    "                            train_instance_count=train_instance_count,\n",
    "                            output_path=s3_output_path,\n",
    "                            base_job_name=job_name_prefix,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            hyperparameters={\n",
    "                                # 3 m5.xl with 4 cores each. We have to leave 1 core for ray scheduler.\n",
    "                                # Don't forget to change this on the basis of instance type.\n",
    "                                \"rl.training.config.num_workers\": (4 * train_instance_count) - 1,\n",
    "                                \"rl.training.config.num_gpus\": 0,\n",
    "                                \"num_iters\": 5000,\n",
    "                                \"num_agents\": 5,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "estimator.fit(wait=False)\n",
    "job_name = estimator.latest_training_job.job_name\n",
    "print(\"Primary Training job: %s\" % job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heterogeneous scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup VPC. It will allow the two SageMaker jobs to communicate over network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default VPC: vpc-f427bc8c\n",
      "Using default security group: ['sg-8c1dddd6']\n",
      "Using default subnets: ['subnet-dd9d5b80', 'subnet-68342523', 'subnet-6c0cf814', 'subnet-405d236b']\n"
     ]
    }
   ],
   "source": [
    "ec2 = boto3.client('ec2')\n",
    "default_vpc = [vpc['VpcId'] for vpc in ec2.describe_vpcs()['Vpcs'] if vpc[\"IsDefault\"] == True][0]\n",
    "\n",
    "default_security_groups = [group[\"GroupId\"] for group in ec2.describe_security_groups()['SecurityGroups'] \\\n",
    "                   if group[\"GroupName\"] == \"default\" and group[\"VpcId\"] == default_vpc]\n",
    "\n",
    "default_subnets = [subnet[\"SubnetId\"] for subnet in ec2.describe_subnets()[\"Subnets\"] \\\n",
    "                  if subnet[\"VpcId\"] == default_vpc and subnet['DefaultForAz']==True]\n",
    "\n",
    "print(\"Using default VPC:\", default_vpc)\n",
    "print(\"Using default security group:\", default_security_groups)\n",
    "print(\"Using default subnets:\", default_subnets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SageMaker job running in VPC mode cannot access S3 resources. So, we need to create a VPC S3 endpoint to allow S3 access from SageMaker container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to attach S3 endpoints to the following route tables: ['rtb-60c6821b']\n",
      "S3 endpoint already exists.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, Markdown\n",
    "# from markdown_helper import generate_help_for_s3_endpoint_permissions, create_s3_endpoint_manually\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "\n",
    "try:\n",
    "    route_tables = [route_table[\"RouteTableId\"] for route_table in ec2.describe_route_tables()['RouteTables']\\\n",
    "                if route_table['VpcId'] == default_vpc]\n",
    "except Exception as e:\n",
    "    if \"UnauthorizedOperation\" in str(e):\n",
    "        display(Markdown(generate_help_for_s3_endpoint_permissions(role)))\n",
    "    else:\n",
    "        display(Markdown(create_s3_endpoint_manually(aws_region, default_vpc)))\n",
    "    raise e\n",
    "\n",
    "print(\"Trying to attach S3 endpoints to the following route tables:\", route_tables)\n",
    "\n",
    "assert len(route_tables) >= 1, \"No route tables were found. Please follow the VPC S3 endpoint creation \"\\\n",
    "                              \"guide by clicking the above link.\"\n",
    "\n",
    "try:\n",
    "    ec2.create_vpc_endpoint(DryRun=False,\n",
    "                           VpcEndpointType=\"Gateway\",\n",
    "                           VpcId=default_vpc,\n",
    "                           ServiceName=\"com.amazonaws.{}.s3\".format(aws_region),\n",
    "                           RouteTableIds=route_tables)\n",
    "    print(\"S3 endpoint created successfully!\")\n",
    "except Exception as e:\n",
    "    if \"RouteAlreadyExists\" in str(e):\n",
    "        print(\"S3 endpoint already exists.\")\n",
    "    elif \"UnauthorizedOperation\" in str(e):\n",
    "#         display(Markdown(generate_help_for_s3_endpoint_permissions(role)))\n",
    "        raise e\n",
    "    else:\n",
    "#         display(Markdown(create_s3_endpoint_manually(aws_region, default_vpc)))\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_image_name = '462105765813.dkr.ecr.{region}.amazonaws.com/sagemaker-rl-ray-container:ray-0.8.2-tf-gpu-py36'.format(region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_cluster_instance_type = \"ml.p2.xlarge\" #\"ml.m5.4xlarge\" # \"ml.p2.xlarge\"\n",
    "primary_cluster_instance_count = 1\n",
    "\n",
    "secondary_cluster_instance_type = \"ml.m5.xlarge\"\n",
    "secondary_cluster_instance_count = 2\n",
    "\n",
    "\n",
    "total_cpus = 16 + 4*2 - 1 # Leave one for ray scheduler\n",
    "# p2.8\n",
    "total_cpus = 4 + 4*2 - 1 # Leave one for ray scheduler\n",
    "\n",
    "total_gpus = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dist-ray-1GPU-11CPUs-ml.p2.xlarge-dqn-async-largebatch'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_prefix = \"dist-ray-%sGPU-%sCPUs-%s-dqn-async-largebatch\" % (total_gpus, total_cpus, primary_cluster_instance_type)\n",
    "s3_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_session = sagemaker.session.Session()\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket) # SDK appends the job name and output folder\n",
    "\n",
    "# We explicitly need to specify these params so that the two jobs can synchronize using the metadata stored here\n",
    "s3_bucket = sage_session.default_bucket()\n",
    "\n",
    "# Make sure that the prefix is empty\n",
    "!aws s3 rm --recursive s3://{s3_bucket}/{s3_prefix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml.m5.xlarge'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondary_cluster_instance_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Training job: anna-ray-heter-dist-1p2x-2m5-dqn-async-2020-04-24-02-51-57-252\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "job_name_prefix = 'anna-ray-heter-dist-1p2x-2m5-dqn-async'\n",
    "# primary_cluster_instance_type = \"ml.m5.xlarge\"\n",
    "primary_cluster_instance_count = 1\n",
    "\n",
    "primary_cluster_estimator = RLEstimator(entry_point=\"train-mabs-dqn-async.py\",\n",
    "                            source_dir='rllib_src',\n",
    "                            dependencies=[\"rllib_common/sagemaker_rl\", \"battlesnake_gym/\"],\n",
    "                            image_name=gpu_image_name, # gpu_image_name if we have\n",
    "                            role=role,\n",
    "                            train_instance_type=primary_cluster_instance_type,\n",
    "                            train_instance_count=primary_cluster_instance_count,\n",
    "                            output_path=s3_output_path,\n",
    "                            base_job_name=job_name_prefix,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            train_max_run=int(3600) * 5, # Maximum runtime in seconds\n",
    "                            hyperparameters={\n",
    "                                \"s3_prefix\": s3_prefix, # Important for syncing\n",
    "                                \"s3_bucket\": s3_bucket, # Important for syncing\n",
    "                                \"aws_region\": boto3.Session().region_name, # Important for S3 connection\n",
    "                                \"rl_cluster_type\": \"primary\", # Important for syncing\n",
    "                                \"rl_num_instances_secondary\": secondary_cluster_instance_count, # Important for syncing\n",
    "                                \"rl.training.config.num_workers\": total_cpus,\n",
    "                                \"rl.training.config.num_gpus\": total_gpus,\n",
    "#                                 \"rl.training.config.train_batch_size\": int(64) * total_cpus,\n",
    "                                \"num_iters\": 5000,\n",
    "                                \"num_agents\": 5,\n",
    "                            },\n",
    "                            subnets=default_subnets, # Required for VPC mode\n",
    "                            security_group_ids=default_security_groups # Required for VPC mode\n",
    "                        )\n",
    "\n",
    "primary_cluster_estimator.fit(wait=False)\n",
    "primary_job_name = primary_cluster_estimator.latest_training_job.job_name\n",
    "print(\"Primary Training job: %s\" % primary_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary Training job: anna-ray-heter-dist-1p2x-2m5-dqn-async-2020-04-24-02-51-57-832\n"
     ]
    }
   ],
   "source": [
    "secondary_cluster_estimator = RLEstimator(entry_point=\"train-mabs-dqn-async.py\",\n",
    "                            source_dir='rllib_src',\n",
    "                            dependencies=[\"rllib_common/sagemaker_rl\", \"battlesnake_gym/\"],\n",
    "                            image_name=cpu_image_name,\n",
    "                            role=role,\n",
    "                            train_instance_type=secondary_cluster_instance_type,\n",
    "                            train_instance_count=secondary_cluster_instance_count,\n",
    "                            output_path=s3_output_path,\n",
    "                            base_job_name=job_name_prefix,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            train_max_run=int(3600) * 5 * 2, # Maximum runtime in seconds\n",
    "                            hyperparameters={\n",
    "                                \"s3_prefix\": s3_prefix, # Important for syncing\n",
    "                                \"s3_bucket\": s3_bucket, # Important for syncing\n",
    "                                \"aws_region\": boto3.Session().region_name, # Important for S3 connection\n",
    "                                \"rl_cluster_type\": \"secondary\", # Important for syncing\n",
    "                                \"rl.training.config.num_workers\": total_cpus,\n",
    "                                \"rl.training.config.num_gpus\": total_gpus,\n",
    "#                                 \"rl.training.config.train_batch_size\": int(64) * total_cpus,\n",
    "                                \"num_iters\": 5000,\n",
    "                                \"num_iters\": 5000,\n",
    "                                \"num_agents\": 5,\n",
    "                            },\n",
    "                            subnets=default_subnets, # Required for VPC mode\n",
    "                            security_group_ids=default_security_groups # Required for VPC mode\n",
    "                        )\n",
    "\n",
    "secondary_cluster_estimator.fit(wait=False)\n",
    "secondary_job_name = secondary_cluster_estimator.latest_training_job.job_name\n",
    "print(\"Secondary Training job: %s\" % secondary_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is the model stored in S3?\n",
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an endpoint to host the policy\n",
    "Firstly, we will delete the previous endpoint and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName='battlesnake-endpoint')\n",
    "sm_client.delete_endpoint_config(EndpointConfigName='battlesnake-endpoint')\n",
    "sm_client.delete_model(ModelName=\"battlesnake-rllib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Copy the endpoint to a central location\n",
    "model_data = \"s3://{}/battlesnake-aws/pretrainedmodels/model.tar.gz\".format(s3_bucket)\n",
    "!aws s3 cp {estimator.model_data} {model_data}\n",
    "\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data=model_data,\n",
    "              role=role,\n",
    "              entry_point=\"inference.py\",\n",
    "              source_dir='rllib_inference/src',\n",
    "              framework_version='2.1.0',\n",
    "              name=\"battlesnake-rllib\",\n",
    "             )\n",
    "\n",
    "if local_mode:\n",
    "    inf_instance_type = 'local'\n",
    "else:\n",
    "    inf_instance_type = \"SAGEMAKER_INFERENCE_INSTANCE_TYPE\"\n",
    "\n",
    "# Deploy an inference endpoint\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=inf_instance_type,#instance_type=\"local\", #\n",
    "                         endpoint_name='battlesnake-endpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the endpoint\n",
    "\n",
    "This example is using single observation for a 5-agent environment \n",
    "The last axis is 12 because the current MultiAgentEnv is concatenating 2 frames\n",
    "5 agent maps + 1 food map = 6 maps total    6 maps * 2 frames = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "data1 = np.zeros(shape=(1, 21, 21, 6), dtype=np.float32).tolist()\n",
    "\n",
    "health_dict = {0: 50, 1: 50}\n",
    "json = {\"turn\": 4,\n",
    "        \"board\": {\n",
    "                \"height\": 15,\n",
    "                \"width\": 15,\n",
    "                \"food\": [],\n",
    "                \"snakes\": []\n",
    "                },\n",
    "            \"you\": {\n",
    "                \"id\": \"snake-id-string\",\n",
    "                \"name\": \"Sneky Snek\",\n",
    "                \"health\": 90,\n",
    "                \"body\": [{\"x\": 1, \"y\": 3}]\n",
    "                }\n",
    "            }\n",
    "\n",
    "before = time()\n",
    "action = predictor.predict({\"state\": data1, \"prev_action\": -1, \n",
    "                           \"prev_reward\": -1, \"seq_lens\": -1,  \n",
    "                           \"all_health\": health_dict, \"json\": json})\n",
    "elapsed = time() - before\n",
    "\n",
    "action_to_take = action[\"outputs\"][\"heuristisc_action\"]\n",
    "print(\"Action to take {}\".format(action_to_take))\n",
    "print(\"Inference took %.2f ms\" % (elapsed*1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
