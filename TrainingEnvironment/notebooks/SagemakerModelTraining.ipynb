{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisations to change the base directory of the entry scripts and to update mxnet to the newest mxnet-mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/examples.//g' battlesnake_src/train.py\n",
    "!sed -i 's/examples.//g' battlesnake_src/networks/agent.py\n",
    "!sed -i '1i import subprocess\\nsubprocess.run([\"pip\",  \"uninstall\", \"mxnet-mkl\", \"-y\"])\\nsubprocess.run([\"pip\",  \"install\", \"mxnet-mkl\", \"--pre\"])' battlesnake_src/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.mxnet.estimator import MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise sagemaker\n",
    "We need to define several parameters prior to running the training job. \n",
    "note: `local_mode` defines whether to run the code within this notebook or to run a sagemaker training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_session = sagemaker.session.Session()\n",
    "s3_bucket = sage_session.default_bucket()  \n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))\n",
    "\n",
    "# run in local_mode on this machine or as a SageMaker TrainingJob\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = 'local'\n",
    "else:\n",
    "    instance_type = \"ml.c5.xlarge\"\n",
    "role = sagemaker.get_execution_role()\n",
    "print(\"Using IAM role arn: {}\".format(role))\n",
    "# only run from SageMaker notebook instance\n",
    "if local_mode:\n",
    "    !/bin/bash ./setup.sh\n",
    "cpu_or_gpu = 'gpu' if instance_type.startswith('ml.p') else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the attributes of the training job\n",
    "Use `job_name_prefix` to identify the sagemaker training job for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a descriptive job name \n",
    "job_name_prefix = 'Battlesnake-job'\n",
    "max_jobs = 3\n",
    "max_parallel_jobs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics to evaluate your training job\n",
    "The regex for this metric was defined based on what is printed in the training script `examples/train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'timesteps', 'Regex': '.*Mean timesteps ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the hyperparameters of your job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'buffer_size': IntegerParameter(1000, 6000),\n",
    "    'update_every': IntegerParameter(10, 20),\n",
    "    'batch_size': IntegerParameter(16, 256),\n",
    "\n",
    "    'lr_start': ContinuousParameter(1e-5, 1e-3),\n",
    "    'lr_factor': ContinuousParameter(0.5, 1.0),\n",
    "    'lr_step': IntegerParameter(5000, 30000),\n",
    "    \n",
    "    'tau': ContinuousParameter(1e-4, 1e-3),\n",
    "    'gamma': ContinuousParameter(0.85, 0.99),\n",
    "    \n",
    "    'depth': IntegerParameter(10, 256),\n",
    "    'depthS': IntegerParameter(10, 256),\n",
    "}\n",
    "\n",
    "static_hyperparameters = {\n",
    "    'qnetwork_type': \"attention\",\n",
    "    'seed': 666,\n",
    "    'number_of_snakes': 4,\n",
    "    'episodes': 22000,\n",
    "    'print_score_steps': 10,\n",
    "    'activation_type': \"softrelu\",\n",
    "    'state_type': 'one_versus_all',\n",
    "    'sequence_length': 2,\n",
    "    'repeat_size': 3,\n",
    "    'kernel_size': 3,\n",
    "    'starting_channels': 6,\n",
    "    'map_size': \"[15, 15]\",\n",
    "    'snake_representation': 'bordered-51s',\n",
    "    'save_model_every': 1000,\n",
    "    'eps_start': 0.99\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines the estimator. Firstly, try run this with `local_model = True` to test your entry_point script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNet(entry_point=\"train.py\",\n",
    "                  source_dir='battlesnake_src',\n",
    "                  dependencies=[\"battlesnake_gym/battlesnake_gym\"],\n",
    "                  role=role,\n",
    "                  train_instance_type=instance_type,\n",
    "                  train_instance_count=1,\n",
    "                  output_path=s3_output_path,\n",
    "                  framework_version=\"1.6.0\",\n",
    "                  py_version='py3',\n",
    "                  base_job_name=job_name_prefix,\n",
    "                  metric_definitions=metric_definitions,\n",
    "                  hyperparameters=static_hyperparameters\n",
    "                 )\n",
    "if local_mode:\n",
    "    estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the Hyperparameter optimisation sagemaker jobs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name='timesteps',\n",
    "                            objective_type='Maximize',\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            max_jobs=max_jobs,\n",
    "                            max_parallel_jobs=max_parallel_jobs,\n",
    "                            base_tuning_job_name=job_name_prefix)\n",
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the best model\n",
    "Obtain an s3 URL of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_training_job = tuner.best_training_job()\n",
    "best_model_s3 = \"{}/{}//output//model.tar.gz\".format(s3_output_path, best_training_job)\n",
    "print(\"Best model location {}\".format(best_model_s3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying an endpoint -WIP\n",
    "DO NOT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_best_job = estimator.attach(tuner.best_training_job(), sage_session)\n",
    "compiled_model = estimator_best_job.compile_model('ml_c5', \n",
    "                                                  {'data' : (1, 3, 384, 512)}, \n",
    "                                                          s3_output_path, \n",
    "                                                      framework='mxnet', framework_version='1.4.1') \n",
    "# Error, Operator _linalg_gemm2 is not supported in frontend MXNet\n",
    "endpoint = compiled_model.deploy(1, 'ml.c5.9xlarge')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
