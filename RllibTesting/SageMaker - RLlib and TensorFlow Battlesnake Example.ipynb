{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook outlines the steps involved in building and deploying a Battlesnake model using Ray RLlib and TensorFlow on Amazon SageMaker.\n",
    "\n",
    "Library versions currently in use:  TensorFlow 2.1, Ray RLlib 0.8.2\n",
    "\n",
    "The model is first trained using multi-agent PPO, and then deployed to a managed _TensorFlow Serving_ SageMaker endpoint that can be used for inference.\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Note:** This is a work-in-progress...\n",
    "\n",
    "### Comments and Known Issues\n",
    "\n",
    "* `cnn_tf.py` currently contains default CNN filters for map sizes ranging 7x7 to 21x21. These default filter sizes can be overriden via the 'conv_filters' config parameter.\n",
    "* The current MultiAgentBattlesnake environment uses 2 frames for each observation. If you only want to use one frame, you'll need to adjust the observation code in `ma_battlesnake.py` accordingly\n",
    "* The original TF model export code in `ray_launcher.py` did not work for TF2.1.\n",
    "  * I switched over to RLlib's export_model() method, which seems to be working here\n",
    "* I have not yet tested RLlib's built-in `{'use_lstm': True}` model parameter, which wraps the CNN in an LSTM. This was working for local training/inference but has not been tested with the SageMaker inference endpoint, yet\n",
    "* Regardless of the number of snakes in the gym, or which policy is 'best', only policy_0 is currently exported as a TF model. Refer to `common/sagemaker_rl/tf_serving_utils.py` and see the comment in the inference section, below\n",
    "* The Ray dashboard fails to start (errors during training) but does not abort the training job\n",
    "* There are many warnings during training - most appear to be benign, but are annoying\n",
    "* Both local-mode and SageMaker-based training and inference have been tested, and appear to be working\n",
    "    * local-mode inference might generate some warnings, but seems to work regardless\n",
    "* GPU training has been tested\n",
    "* GPU inference has not been tested\n",
    "* Single-instance training has been tested. Distributed multi-instance RLlib training has not yet been tested.\n",
    "* Although the hosted model is able to provide predictions, I haven't yet verified that the predictions are correct or useful.\n",
    "* The default hyperparameters are unlikely to generate an impressive model. Modify the hyperparameters and rewards if you are hoping to see something cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket path: s3://sagemaker-us-west-2-412868550678/\n"
     ]
    }
   ],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "s3_bucket = sm_session.default_bucket()\n",
    "\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::412868550678:role/BattlesnakeEnvironment-jo-NotebookInstanceExecutio-1ESEZD1FEJJ5V\n"
     ]
    }
   ],
   "source": [
    "job_name_prefix = 'battlesnake-rllib-ppo'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change local_mode to True if you want to do local training within this Notebook instance\n",
    "# Otherwise, we'll spin-up a SageMaker training instance to handle the training\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = 'local'\n",
    "else:\n",
    "    instance_type = \"ml.m5.4xlarge\"\n",
    "    \n",
    "# If training locally, do some Docker housekeeping..\n",
    "if local_mode:\n",
    "    !/bin/bash ./common/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the new TF v2.1 / Ray RLlib 0.8.2 container\n",
    "#    Adjust 'cpu' or 'gpu' in the image name, as required\n",
    "image_name = '462105765813.dkr.ecr.us-west-2.amazonaws.com/sagemaker-rl-ray-container:ray-0.8.2-tf-cpu-py36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-30 23:14:59 Starting - Starting the training job...\n",
      "2020-03-30 23:15:02 Starting - Launching requested ML instances......\n",
      "2020-03-30 23:16:05 Starting - Preparing the instances for training...\n",
      "2020-03-30 23:16:45 Downloading - Downloading input data\n",
      "2020-03-30 23:16:45 Training - Downloading the training image......\n",
      "2020-03-30 23:17:45 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-03-30 23:17:48,709 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-03-30 23:17:48,716 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-30 23:17:48,854 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-30 23:17:48,869 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-30 23:17:48,883 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-30 23:17:48,893 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator\": \"RLEstimator\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"num_iters\": 10,\n",
      "        \"num_agents\": 5,\n",
      "        \"map_height\": 11\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"battlesnake-rllib-ppo-2020-03-30-23-14-59-441\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-412868550678/battlesnake-rllib-ppo-2020-03-30-23-14-59-441/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train-mabs\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train-mabs.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"map_height\":11,\"num_agents\":5,\"num_iters\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train-mabs.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train-mabs\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-412868550678/battlesnake-rllib-ppo-2020-03-30-23-14-59-441/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"map_height\":11,\"num_agents\":5,\"num_iters\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"battlesnake-rllib-ppo-2020-03-30-23-14-59-441\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-412868550678/battlesnake-rllib-ppo-2020-03-30-23-14-59-441/source/sourcedir.tar.gz\",\"module_name\":\"train-mabs\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-mabs.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--map_height\",\"11\",\"--num_agents\",\"5\",\"--num_iters\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ITERS=10\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_AGENTS=5\u001b[0m\n",
      "\u001b[34mSM_HP_MAP_HEIGHT=11\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train-mabs.py --map_height 11 --num_agents 5 --num_iters 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-03-30 23:17:51,840#011INFO resource_spec.py:212 -- Starting Ray with 33.59 GiB memory available for workers and up to 16.81 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\u001b[0m\n",
      "\u001b[34m2020-03-30 23:17:52,238#011INFO services.py:1078 -- View the Ray dashboard at #033[1m#033[32mlocalhost:8265#033[39m#033[22m\u001b[0m\n",
      "\u001b[34mNo checkpoint path specified. Training from scratch.\u001b[0m\n",
      "\u001b[34mImportant! Ray with version <=7.2 may report \"Did not find checkpoint file\" even if the experiment is actually restored successfully. If restoration is expected, please check \"training_iteration\" in the experiment info to confirm.\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 2.9/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc   |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  |       |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-03-30 23:17:53,457#011WARNING worker.py:1058 -- The dashboard on node ip-10-0-203-14.us-west-2.compute.internal failed with the following error:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1062, in create_server\n",
      "    sock.bind(sa)\u001b[0m\n",
      "\u001b[34mOSError: [Errno 99] Cannot assign requested address\n",
      "\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ray/dashboard/dashboard.py\", line 920, in <module>\n",
      "    dashboard.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ray/dashboard/dashboard.py\", line 368, in run\n",
      "    aiohttp.web.run_app(self.app, host=self.host, port=self.port)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/web.py\", line 433, in run_app\n",
      "    reuse_port=reuse_port))\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 484, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/web.py\", line 359, in _run_app\n",
      "    await site.start()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/web_runner.py\", line 104, in start\n",
      "    reuse_port=self._reuse_port)\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1066, in create_server\n",
      "    % (sa, err.strerror.lower()))\u001b[0m\n",
      "\u001b[34mOSError: [Errno 99] error while attempting to bind on address ('::1', 8265, 0, 0): cannot assign requested address\n",
      "\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m 2020-03-30 23:17:55,242#011INFO trainer.py:420 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m 2020-03-30 23:17:55,255#011INFO trainer.py:580 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m 2020-03-30 23:18:34,055#011INFO trainable.py:178 -- _setup took 38.812 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_adfaf3f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-30_23-19-38\n",
      "  done: false\n",
      "  episode_len_mean: 4.444401394808214\n",
      "  episode_reward_max: 24.0\n",
      "  episode_reward_mean: -1.8167376985664472\n",
      "  episode_reward_min: -15.0\n",
      "  episodes_this_iter: 2581\n",
      "  episodes_total: 2581\n",
      "  experiment_id: a9b94a489f7944fdb3fdbbf082923e9c\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-203-14.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 23245.93\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.363232135772705\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02302892506122589\n",
      "        policy_loss: -0.06265441328287125\n",
      "        total_loss: 1.9916490316390991\n",
      "        vf_explained_var: 0.2899351418018341\n",
      "        vf_loss: 2.0496976375579834\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3661329746246338\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01930420473217964\n",
      "        policy_loss: -0.05491521582007408\n",
      "        total_loss: 1.933232307434082\n",
      "        vf_explained_var: 0.30891406536102295\n",
      "        vf_loss: 1.9842866659164429\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3645621538162231\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021529067307710648\n",
      "        policy_loss: -0.05917346850037575\n",
      "        total_loss: 1.9618144035339355\n",
      "        vf_explained_var: 0.2892332077026367\n",
      "        vf_loss: 2.0166821479797363\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3642209768295288\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020641926676034927\n",
      "        policy_loss: -0.056101132184267044\n",
      "        total_loss: 1.993015170097351\n",
      "        vf_explained_var: 0.28756552934646606\n",
      "        vf_loss: 2.044987916946411\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3633830547332764\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02249605394899845\n",
      "        policy_loss: -0.06092672795057297\n",
      "        total_loss: 1.9562065601348877\n",
      "        vf_explained_var: 0.2785801291465759\n",
      "        vf_loss: 2.012634038925171\n",
      "    load_time_ms: 2376.995\n",
      "    num_steps_sampled: 11520\n",
      "    num_steps_trained: 11520\n",
      "    sample_time_ms: 11749.961\n",
      "    update_time_ms: 22387.359\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.203.14\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.51011235955056\n",
      "    ram_util_percent: 17.57078651685393\n",
      "  pid: 151\n",
      "  policy_reward_max:\n",
      "    policy_0: 14.0\n",
      "    policy_1: 17.0\n",
      "    policy_2: 19.0\n",
      "    policy_3: 15.0\n",
      "    policy_4: 13.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: -0.38008523827973656\n",
      "    policy_1: -0.31576908175125923\n",
      "    policy_2: -0.4176675707090275\n",
      "    policy_3: -0.3316543975203409\n",
      "    policy_4: -0.3715614103060829\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.3501124282038643\n",
      "    mean_inference_ms: 22.35431781248181\n",
      "    mean_processing_ms: 2.847197616577839\n",
      "  time_since_restore: 61.24548387527466\n",
      "  time_this_iter_s: 61.24548387527466\n",
      "  time_total_s: 61.24548387527466\n",
      "  timestamp: 1585610378\n",
      "  timesteps_since_restore: 11520\n",
      "  timesteps_this_iter: 11520\n",
      "  timesteps_total: 11520\n",
      "  training_iteration: 1\n",
      "  trial_id: adfaf3f0\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.6/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc             |   reward |   total time (s) |    ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-----------------+----------+------------------+-------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  | 10.0.203.14:151 | -1.81674 |          61.2455 | 11520 |      1 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_adfaf3f0:\u001b[0m\n",
      "\u001b[34m  custom_metrics: {}\n",
      "  date: 2020-03-30_23-20-03\n",
      "  done: false\n",
      "  episode_len_mean: 4.706050695012265\n",
      "  episode_reward_max: 31.0\n",
      "  episode_reward_mean: -1.0919869174161898\n",
      "  episode_reward_min: -15.0\n",
      "  episodes_this_iter: 2446\n",
      "  episodes_total: 5027\n",
      "  experiment_id: a9b94a489f7944fdb3fdbbf082923e9c\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-203-14.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 19115.783\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3204296827316284\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029687147587537766\n",
      "        policy_loss: -0.09649979323148727\n",
      "        total_loss: 2.476313591003418\n",
      "        vf_explained_var: 0.32056549191474915\n",
      "        vf_loss: 2.5639071464538574\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3231121301651\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0317646823823452\n",
      "        policy_loss: -0.09676211327314377\n",
      "        total_loss: 2.184974431991577\n",
      "        vf_explained_var: 0.3034444749355316\n",
      "        vf_loss: 2.275383472442627\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3189358711242676\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029309429228305817\n",
      "        policy_loss: -0.09879212081432343\n",
      "        total_loss: 2.5416383743286133\n",
      "        vf_explained_var: 0.30081236362457275\n",
      "        vf_loss: 2.6316375732421875\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3178691864013672\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029905062168836594\n",
      "        policy_loss: -0.09599733352661133\n",
      "        total_loss: 2.440422296524048\n",
      "        vf_explained_var: 0.3047964870929718\n",
      "        vf_loss: 2.5274481773376465\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.317662000656128\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.027812838554382324\n",
      "        policy_loss: -0.091594398021698\n",
      "        total_loss: 2.5769050121307373\n",
      "        vf_explained_var: 0.30654436349868774\n",
      "        vf_loss: 2.6601555347442627\n",
      "    load_time_ms: 1374.22\n",
      "    num_steps_sampled: 23040\n",
      "    num_steps_trained: 23040\n",
      "    sample_time_ms: 10883.599\n",
      "    update_time_ms: 11201.93\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 10.0.203.14\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.049999999999997\n",
      "    ram_util_percent: 19.20588235294118\n",
      "  pid: 151\n",
      "  policy_reward_max:\n",
      "    policy_0: 16.0\n",
      "    policy_1: 16.0\n",
      "    policy_2: 18.0\n",
      "    policy_3: 19.0\n",
      "    policy_4: 19.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: -0.23712183156173344\n",
      "    policy_1: -0.42804578904333607\n",
      "    policy_2: -0.20932134096484056\n",
      "    policy_3: -0.16271463614063778\n",
      "    policy_4: -0.05478331970564186\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.3621957227357564\n",
      "    mean_inference_ms: 21.46926933963637\n",
      "    mean_processing_ms: 2.8667404220056425\n",
      "  time_since_restore: 86.68043231964111\n",
      "  time_this_iter_s: 25.434948444366455\n",
      "  time_total_s: 86.68043231964111\n",
      "  timestamp: 1585610403\n",
      "  timesteps_since_restore: 23040\n",
      "  timesteps_this_iter: 11520\n",
      "  timesteps_total: 23040\n",
      "  training_iteration: 2\n",
      "  trial_id: adfaf3f0\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.6/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc             |   reward |   total time (s) |    ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-----------------+----------+------------------+-------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  | 10.0.203.14:151 | -1.09199 |          86.6804 | 23040 |      2 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_adfaf3f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-30_23-20-29\n",
      "  done: false\n",
      "  episode_len_mean: 5.723743155798905\n",
      "  episode_reward_max: 45.0\n",
      "  episode_reward_mean: 1.8317570930811349\n",
      "  episode_reward_min: -15.0\n",
      "  episodes_this_iter: 2009\n",
      "  episodes_total: 7036\n",
      "  experiment_id: a9b94a489f7944fdb3fdbbf082923e9c\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-203-14.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 17807.026\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.26991868019104\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029696935787796974\n",
      "        policy_loss: -0.10216989368200302\n",
      "        total_loss: 3.2120463848114014\n",
      "        vf_explained_var: 0.3512663245201111\n",
      "        vf_loss: 3.3008525371551514\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2626373767852783\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03364204987883568\n",
      "        policy_loss: -0.10735519975423813\n",
      "        total_loss: 2.8972127437591553\n",
      "        vf_explained_var: 0.34031832218170166\n",
      "        vf_loss: 2.9944756031036377\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2603334188461304\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030994508415460587\n",
      "        policy_loss: -0.10883306711912155\n",
      "        total_loss: 3.1380882263183594\n",
      "        vf_explained_var: 0.3339236080646515\n",
      "        vf_loss: 3.23297381401062\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2698659896850586\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.027685875073075294\n",
      "        policy_loss: -0.10201475024223328\n",
      "        total_loss: 3.0997023582458496\n",
      "        vf_explained_var: 0.34412747621536255\n",
      "        vf_loss: 3.189258575439453\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.258226990699768\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02937597781419754\n",
      "        policy_loss: -0.10496833920478821\n",
      "        total_loss: 3.5387234687805176\n",
      "        vf_explained_var: 0.32472702860832214\n",
      "        vf_loss: 3.6304728984832764\n",
      "    load_time_ms: 1041.195\n",
      "    num_steps_sampled: 34560\n",
      "    num_steps_trained: 34560\n",
      "    sample_time_ms: 10468.455\n",
      "    update_time_ms: 7474.694\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.0.203.14\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.205714285714283\n",
      "    ram_util_percent: 19.29428571428571\n",
      "  pid: 151\n",
      "  policy_reward_max:\n",
      "    policy_0: 26.0\n",
      "    policy_1: 19.0\n",
      "    policy_2: 25.0\n",
      "    policy_3: 18.0\n",
      "    policy_4: 24.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 0.21951219512195122\n",
      "    policy_1: 0.30612244897959184\n",
      "    policy_2: 0.35689397710303633\n",
      "    policy_3: 0.5634644101543056\n",
      "    policy_4: 0.38576406172224986\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.3561049291655227\n",
      "    mean_inference_ms: 20.91441551761079\n",
      "    mean_processing_ms: 2.775630327632553\n",
      "  time_since_restore: 111.94273161888123\n",
      "  time_this_iter_s: 25.262299299240112\n",
      "  time_total_s: 111.94273161888123\n",
      "  timestamp: 1585610429\n",
      "  timesteps_since_restore: 34560\n",
      "  timesteps_this_iter: 11520\n",
      "  timesteps_total: 34560\n",
      "  training_iteration: 3\n",
      "  trial_id: adfaf3f0\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.7/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc             |   reward |   total time (s) |    ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-----------------+----------+------------------+-------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  | 10.0.203.14:151 |  1.83176 |          111.943 | 34560 |      3 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_adfaf3f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-30_23-20-56\n",
      "  done: false\n",
      "  episode_len_mean: 7.425435765009683\n",
      "  episode_reward_max: 43.0\n",
      "  episode_reward_mean: 6.8437701743060035\n",
      "  episode_reward_min: -14.0\n",
      "  episodes_this_iter: 1549\n",
      "  episodes_total: 8585\n",
      "  experiment_id: a9b94a489f7944fdb3fdbbf082923e9c\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-203-14.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 17469.341\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2121386528015137\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026829876005649567\n",
      "        policy_loss: -0.10194658488035202\n",
      "        total_loss: 3.930338144302368\n",
      "        vf_explained_var: 0.3929963707923889\n",
      "        vf_loss: 4.014174938201904\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.199539065361023\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03272281959652901\n",
      "        policy_loss: -0.10430575162172318\n",
      "        total_loss: 4.093480587005615\n",
      "        vf_explained_var: 0.3997851014137268\n",
      "        vf_loss: 4.183060646057129\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2035220861434937\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.027225269004702568\n",
      "        policy_loss: -0.10274914652109146\n",
      "        total_loss: 4.123898506164551\n",
      "        vf_explained_var: 0.40792813897132874\n",
      "        vf_loss: 4.208270072937012\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2100259065628052\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025657564401626587\n",
      "        policy_loss: -0.10448013246059418\n",
      "        total_loss: 4.3954854011535645\n",
      "        vf_explained_var: 0.39021432399749756\n",
      "        vf_loss: 4.482646465301514\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1938704252243042\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02699301950633526\n",
      "        policy_loss: -0.1014220342040062\n",
      "        total_loss: 4.355556011199951\n",
      "        vf_explained_var: 0.39538782835006714\n",
      "        vf_loss: 4.438757419586182\n",
      "    load_time_ms: 883.727\n",
      "    num_steps_sampled: 46080\n",
      "    num_steps_trained: 46080\n",
      "    sample_time_ms: 10321.138\n",
      "    update_time_ms: 5610.382\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 10.0.203.14\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.71111111111111\n",
      "    ram_util_percent: 19.349999999999994\n",
      "  pid: 151\n",
      "  policy_reward_max:\n",
      "    policy_0: 20.0\n",
      "    policy_1: 20.0\n",
      "    policy_2: 25.0\n",
      "    policy_3: 23.0\n",
      "    policy_4: 23.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 1.145900581020013\n",
      "    policy_1: 1.1465461588121368\n",
      "    policy_2: 1.551323434473854\n",
      "    policy_3: 1.420916720464816\n",
      "    policy_4: 1.579083279535184\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.3629057377804312\n",
      "    mean_inference_ms: 20.84120473989383\n",
      "    mean_processing_ms: 2.685629153695646\n",
      "  time_since_restore: 138.7431194782257\n",
      "  time_this_iter_s: 26.800387859344482\n",
      "  time_total_s: 138.7431194782257\n",
      "  timestamp: 1585610456\n",
      "  timesteps_since_restore: 46080\n",
      "  timesteps_this_iter: 11520\n",
      "  timesteps_total: 46080\n",
      "  training_iteration: 4\n",
      "  trial_id: adfaf3f0\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.7/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc             |   reward |   total time (s) |    ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-----------------+----------+------------------+-------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  | 10.0.203.14:151 |  6.84377 |          138.743 | 46080 |      4 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_adfaf3f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-30_23-21-21\n",
      "  done: false\n",
      "  episode_len_mean: 9.37315875613748\n",
      "  episode_reward_max: 73.0\n",
      "  episode_reward_mean: 12.77823240589198\n",
      "  episode_reward_min: -11.0\n",
      "  episodes_this_iter: 1222\n",
      "  episodes_total: 9807\n",
      "  experiment_id: a9b94a489f7944fdb3fdbbf082923e9c\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-203-14.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 16956.457\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1598961353302002\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020781029015779495\n",
      "        policy_loss: -0.09006796777248383\n",
      "        total_loss: 5.477269172668457\n",
      "        vf_explained_var: 0.4632546305656433\n",
      "        vf_loss: 5.5462965965271\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1488795280456543\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.027441324666142464\n",
      "        policy_loss: -0.09591002762317657\n",
      "        total_loss: 5.26867151260376\n",
      "        vf_explained_var: 0.4606492817401886\n",
      "        vf_loss: 5.346058368682861\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1541388034820557\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021843113005161285\n",
      "        policy_loss: -0.09372653067111969\n",
      "        total_loss: 5.603742599487305\n",
      "        vf_explained_var: 0.4577031135559082\n",
      "        vf_loss: 5.675353527069092\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.157124400138855\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.022014928981661797\n",
      "        policy_loss: -0.09598466753959656\n",
      "        total_loss: 5.950660705566406\n",
      "        vf_explained_var: 0.45891833305358887\n",
      "        vf_loss: 6.024354457855225\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.156812071800232\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.022360799834132195\n",
      "        policy_loss: -0.0973971039056778\n",
      "        total_loss: 5.837283134460449\n",
      "        vf_explained_var: 0.4486675262451172\n",
      "        vf_loss: 5.9120402336120605\n",
      "    load_time_ms: 780.242\n",
      "    num_steps_sampled: 57600\n",
      "    num_steps_trained: 57600\n",
      "    sample_time_ms: 10255.462\n",
      "    update_time_ms: 4492.133\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.0.203.14\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.534285714285712\n",
      "    ram_util_percent: 19.285714285714278\n",
      "  pid: 151\n",
      "  policy_reward_max:\n",
      "    policy_0: 32.0\n",
      "    policy_1: 31.0\n",
      "    policy_2: 34.0\n",
      "    policy_3: 29.0\n",
      "    policy_4: 31.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 2.2569558101472995\n",
      "    policy_1: 2.162847790507365\n",
      "    policy_2: 2.7397708674304417\n",
      "    policy_3: 2.997545008183306\n",
      "    policy_4: 2.621112929623568\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.3736490746345476\n",
      "    mean_inference_ms: 20.892242705134066\n",
      "    mean_processing_ms: 2.5998275140089753\n",
      "  time_since_restore: 164.08308124542236\n",
      "  time_this_iter_s: 25.339961767196655\n",
      "  time_total_s: 164.08308124542236\n",
      "  timestamp: 1585610481\n",
      "  timesteps_since_restore: 57600\n",
      "  timesteps_this_iter: 11520\n",
      "  timesteps_total: 57600\n",
      "  training_iteration: 5\n",
      "  trial_id: adfaf3f0\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.7/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc             |   reward |   total time (s) |    ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-----------------+----------+------------------+-------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  | 10.0.203.14:151 |  12.7782 |          164.083 | 57600 |      5 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_adfaf3f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-30_23-21-47\n",
      "  done: false\n",
      "  episode_len_mean: 12.227321237993596\n",
      "  episode_reward_max: 102.0\n",
      "  episode_reward_mean: 20.885805763073638\n",
      "  episode_reward_min: -11.0\n",
      "  episodes_this_iter: 937\n",
      "  episodes_total: 10744\n",
      "  experiment_id: a9b94a489f7944fdb3fdbbf082923e9c\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-203-14.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 16651.839\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1154111623764038\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016477925702929497\n",
      "        policy_loss: -0.08084128797054291\n",
      "        total_loss: 8.383724212646484\n",
      "        vf_explained_var: 0.5232816934585571\n",
      "        vf_loss: 8.439539909362793\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.126663327217102\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02176225371658802\n",
      "        policy_loss: -0.08654750883579254\n",
      "        total_loss: 5.671366214752197\n",
      "        vf_explained_var: 0.5511931777000427\n",
      "        vf_loss: 5.735878944396973\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1155071258544922\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01697433553636074\n",
      "        policy_loss: -0.08152493089437485\n",
      "        total_loss: 7.545469284057617\n",
      "        vf_explained_var: 0.5347797274589539\n",
      "        vf_loss: 7.6012139320373535\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1167807579040527\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01585349254310131\n",
      "        policy_loss: -0.08113032579421997\n",
      "        total_loss: 8.19190502166748\n",
      "        vf_explained_var: 0.5142620801925659\n",
      "        vf_loss: 8.248958587646484\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1169192790985107\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016497541218996048\n",
      "        policy_loss: -0.08689987659454346\n",
      "        total_loss: 7.168522357940674\n",
      "        vf_explained_var: 0.5164130330085754\n",
      "        vf_loss: 7.230367183685303\n",
      "    load_time_ms: 711.348\n",
      "    num_steps_sampled: 69120\n",
      "    num_steps_trained: 69120\n",
      "    sample_time_ms: 10173.425\n",
      "    update_time_ms: 3746.568\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 10.0.203.14\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.411764705882355\n",
      "    ram_util_percent: 19.34705882352941\n",
      "  pid: 151\n",
      "  policy_reward_max:\n",
      "    policy_0: 43.0\n",
      "    policy_1: 38.0\n",
      "    policy_2: 44.0\n",
      "    policy_3: 41.0\n",
      "    policy_4: 39.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 3.9626467449306295\n",
      "    policy_1: 3.1526147278548557\n",
      "    policy_2: 5.0811099252934895\n",
      "    policy_3: 4.691568836712913\n",
      "    policy_4: 3.9978655282817503\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.377963432059245\n",
      "    mean_inference_ms: 20.885797997758164\n",
      "    mean_processing_ms: 2.5081642687029695\n",
      "  time_since_restore: 189.39041256904602\n",
      "  time_this_iter_s: 25.307331323623657\n",
      "  time_total_s: 189.39041256904602\n",
      "  timestamp: 1585610507\n",
      "  timesteps_since_restore: 69120\n",
      "  timesteps_this_iter: 11520\n",
      "  timesteps_total: 69120\n",
      "  training_iteration: 6\n",
      "  trial_id: adfaf3f0\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.7/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc             |   reward |   total time (s) |    ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-----------------+----------+------------------+-------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  | 10.0.203.14:151 |  20.8858 |           189.39 | 69120 |      6 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_adfaf3f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-30_23-22-12\n",
      "  done: false\n",
      "  episode_len_mean: 14.672611464968153\n",
      "  episode_reward_max: 147.0\n",
      "  episode_reward_mean: 27.628025477707006\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 785\n",
      "  episodes_total: 11529\n",
      "  experiment_id: a9b94a489f7944fdb3fdbbf082923e9c\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-203-14.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 16427.195\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.096172571182251\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015147569589316845\n",
      "        policy_loss: -0.07526379078626633\n",
      "        total_loss: 10.147666931152344\n",
      "        vf_explained_var: 0.5815597772598267\n",
      "        vf_loss: 10.19992446899414\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0992470979690552\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017056871205568314\n",
      "        policy_loss: -0.07899376004934311\n",
      "        total_loss: 7.307549476623535\n",
      "        vf_explained_var: 0.5985720753669739\n",
      "        vf_loss: 7.360637664794922\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1000463962554932\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01552370935678482\n",
      "        policy_loss: -0.07695989310741425\n",
      "        total_loss: 9.390169143676758\n",
      "        vf_explained_var: 0.5757086873054504\n",
      "        vf_loss: 9.44355297088623\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0805494785308838\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014878376387059689\n",
      "        policy_loss: -0.07599508762359619\n",
      "        total_loss: 9.379022598266602\n",
      "        vf_explained_var: 0.5730571150779724\n",
      "        vf_loss: 9.432421684265137\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.085835576057434\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016082225367426872\n",
      "        policy_loss: -0.08131594210863113\n",
      "        total_loss: 8.791457176208496\n",
      "        vf_explained_var: 0.5722440481185913\n",
      "        vf_loss: 8.848347663879395\n",
      "    load_time_ms: 662.353\n",
      "    num_steps_sampled: 80640\n",
      "    num_steps_trained: 80640\n",
      "    sample_time_ms: 10086.019\n",
      "    update_time_ms: 3213.911\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 10.0.203.14\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.147058823529417\n",
      "    ram_util_percent: 19.358823529411758\n",
      "  pid: 151\n",
      "  policy_reward_max:\n",
      "    policy_0: 62.0\n",
      "    policy_1: 36.0\n",
      "    policy_2: 48.0\n",
      "    policy_3: 54.0\n",
      "    policy_4: 55.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 5.443312101910828\n",
      "    policy_1: 4.382165605095541\n",
      "    policy_2: 6.126114649681528\n",
      "    policy_3: 6.271337579617835\n",
      "    policy_4: 5.405095541401274\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.3762880278561311\n",
      "    mean_inference_ms: 20.819503795844987\n",
      "    mean_processing_ms: 2.425452015312641\n",
      "  time_since_restore: 214.44877672195435\n",
      "  time_this_iter_s: 25.058364152908325\n",
      "  time_total_s: 214.44877672195435\n",
      "  timestamp: 1585610532\n",
      "  timesteps_since_restore: 80640\n",
      "  timesteps_this_iter: 11520\n",
      "  timesteps_total: 80640\n",
      "  training_iteration: 7\n",
      "  trial_id: adfaf3f0\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.7/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc             |   reward |   total time (s) |    ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-----------------+----------+------------------+-------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  | 10.0.203.14:151 |   27.628 |          214.449 | 80640 |      7 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_adfaf3f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-30_23-22-37\n",
      "  done: false\n",
      "  episode_len_mean: 17.976038338658146\n",
      "  episode_reward_max: 156.0\n",
      "  episode_reward_mean: 36.54792332268371\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 626\n",
      "  episodes_total: 12155\n",
      "  experiment_id: a9b94a489f7944fdb3fdbbf082923e9c\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-203-14.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 16237.909\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0869203805923462\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014845700934529305\n",
      "        policy_loss: -0.07067005336284637\n",
      "        total_loss: 11.110300064086914\n",
      "        vf_explained_var: 0.6460654139518738\n",
      "        vf_loss: 11.158422470092773\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.082467794418335\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015342377126216888\n",
      "        policy_loss: -0.07574696093797684\n",
      "        total_loss: 10.065792083740234\n",
      "        vf_explained_var: 0.6331192255020142\n",
      "        vf_loss: 10.11823844909668\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0678409337997437\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01526197325438261\n",
      "        policy_loss: -0.07415146380662918\n",
      "        total_loss: 12.58079719543457\n",
      "        vf_explained_var: 0.6144294738769531\n",
      "        vf_loss: 12.631768226623535\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0635262727737427\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015089316293597221\n",
      "        policy_loss: -0.07579415291547775\n",
      "        total_loss: 11.669641494750977\n",
      "        vf_explained_var: 0.618626058101654\n",
      "        vf_loss: 11.722518920898438\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0445029735565186\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014942990615963936\n",
      "        policy_loss: -0.07312905788421631\n",
      "        total_loss: 12.031269073486328\n",
      "        vf_explained_var: 0.596949577331543\n",
      "        vf_loss: 12.081701278686523\n",
      "    load_time_ms: 625.564\n",
      "    num_steps_sampled: 92160\n",
      "    num_steps_trained: 92160\n",
      "    sample_time_ms: 10023.319\n",
      "    update_time_ms: 2815.221\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 10.0.203.14\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.98235294117647\n",
      "    ram_util_percent: 19.42941176470588\n",
      "  pid: 151\n",
      "  policy_reward_max:\n",
      "    policy_0: 73.0\n",
      "    policy_1: 63.0\n",
      "    policy_2: 80.0\n",
      "    policy_3: 56.0\n",
      "    policy_4: 62.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 6.207667731629393\n",
      "    policy_1: 6.522364217252396\n",
      "    policy_2: 8.191693290734824\n",
      "    policy_3: 7.785942492012779\n",
      "    policy_4: 7.840255591054313\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.376262633950315\n",
      "    mean_inference_ms: 20.78410090341164\n",
      "    mean_processing_ms: 2.3591845361972483\n",
      "  time_since_restore: 239.3666398525238\n",
      "  time_this_iter_s: 24.917863130569458\n",
      "  time_total_s: 239.3666398525238\n",
      "  timestamp: 1585610557\n",
      "  timesteps_since_restore: 92160\n",
      "  timesteps_this_iter: 11520\n",
      "  timesteps_total: 92160\n",
      "  training_iteration: 8\n",
      "  trial_id: adfaf3f0\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.7/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc             |   reward |   total time (s) |    ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-----------------+----------+------------------+-------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  | 10.0.203.14:151 |  36.5479 |          239.367 | 92160 |      8 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+-------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_adfaf3f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-30_23-23-02\n",
      "  done: false\n",
      "  episode_len_mean: 21.80263157894737\n",
      "  episode_reward_max: 218.0\n",
      "  episode_reward_mean: 46.32706766917293\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 532\n",
      "  episodes_total: 12687\n",
      "  experiment_id: a9b94a489f7944fdb3fdbbf082923e9c\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-203-14.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 16155.623\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0694812536239624\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015198935754597187\n",
      "        policy_loss: -0.06938232481479645\n",
      "        total_loss: 11.654183387756348\n",
      "        vf_explained_var: 0.6834912300109863\n",
      "        vf_loss: 11.700480461120605\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0618395805358887\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01506287232041359\n",
      "        policy_loss: -0.06887839734554291\n",
      "        total_loss: 11.936095237731934\n",
      "        vf_explained_var: 0.6870493292808533\n",
      "        vf_loss: 11.982097625732422\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0422122478485107\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014586015604436398\n",
      "        policy_loss: -0.06854255497455597\n",
      "        total_loss: 13.760169982910156\n",
      "        vf_explained_var: 0.6683254837989807\n",
      "        vf_loss: 13.806559562683105\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.039969801902771\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014529576525092125\n",
      "        policy_loss: -0.07008715718984604\n",
      "        total_loss: 13.959732055664062\n",
      "        vf_explained_var: 0.6495538949966431\n",
      "        vf_loss: 14.007752418518066\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0461872816085815\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01519318949431181\n",
      "        policy_loss: -0.07418428361415863\n",
      "        total_loss: 14.459115028381348\n",
      "        vf_explained_var: 0.6537595987319946\n",
      "        vf_loss: 14.51022720336914\n",
      "    load_time_ms: 596.345\n",
      "    num_steps_sampled: 103680\n",
      "    num_steps_trained: 103680\n",
      "    sample_time_ms: 9977.569\n",
      "    update_time_ms: 2504.49\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 10.0.203.14\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.88529411764706\n",
      "    ram_util_percent: 19.452941176470585\n",
      "  pid: 151\n",
      "  policy_reward_max:\n",
      "    policy_0: 103.0\n",
      "    policy_1: 57.0\n",
      "    policy_2: 67.0\n",
      "    policy_3: 63.0\n",
      "    policy_4: 96.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 8.411654135338345\n",
      "    policy_1: 8.678571428571429\n",
      "    policy_2: 10.389097744360901\n",
      "    policy_3: 10.114661654135338\n",
      "    policy_4: 8.733082706766917\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.3715655595467786\n",
      "    mean_inference_ms: 20.76760735614629\n",
      "    mean_processing_ms: 2.2946680959362507\n",
      "  time_since_restore: 264.8857536315918\n",
      "  time_this_iter_s: 25.519113779067993\n",
      "  time_total_s: 264.8857536315918\n",
      "  timestamp: 1585610582\n",
      "  timesteps_since_restore: 103680\n",
      "  timesteps_this_iter: 11520\n",
      "  timesteps_total: 103680\n",
      "  training_iteration: 9\n",
      "  trial_id: adfaf3f0\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.7/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc             |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-----------------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  | 10.0.203.14:151 |  46.3271 |          264.886 | 103680 |      9 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_adfaf3f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-30_23-23-28\n",
      "  done: true\n",
      "  episode_len_mean: 26.604597701149427\n",
      "  episode_reward_max: 275.0\n",
      "  episode_reward_mean: 58.10804597701149\n",
      "  episode_reward_min: -4.0\n",
      "  episodes_this_iter: 435\n",
      "  episodes_total: 13122\n",
      "  experiment_id: a9b94a489f7944fdb3fdbbf082923e9c\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-203-14.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 16105.261\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0320608615875244\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014027630910277367\n",
      "        policy_loss: -0.06414832174777985\n",
      "        total_loss: 13.8328857421875\n",
      "        vf_explained_var: 0.742635190486908\n",
      "        vf_loss: 13.87572956085205\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0780476331710815\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014126501977443695\n",
      "        policy_loss: -0.06614368408918381\n",
      "        total_loss: 13.027506828308105\n",
      "        vf_explained_var: 0.7292524576187134\n",
      "        vf_loss: 13.072195053100586\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0181171894073486\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014328008517622948\n",
      "        policy_loss: -0.06746608763933182\n",
      "        total_loss: 15.31545639038086\n",
      "        vf_explained_var: 0.7018760442733765\n",
      "        vf_loss: 15.361162185668945\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0280050039291382\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013703436590731144\n",
      "        policy_loss: -0.0672941654920578\n",
      "        total_loss: 16.608007431030273\n",
      "        vf_explained_var: 0.7072635293006897\n",
      "        vf_loss: 16.654489517211914\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0054104328155518\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014276215806603432\n",
      "        policy_loss: -0.06570057570934296\n",
      "        total_loss: 15.661788940429688\n",
      "        vf_explained_var: 0.6998019814491272\n",
      "        vf_loss: 15.70580768585205\n",
      "    load_time_ms: 574.329\n",
      "    num_steps_sampled: 115200\n",
      "    num_steps_trained: 115200\n",
      "    sample_time_ms: 9980.861\n",
      "    update_time_ms: 2256.432\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.0.203.14\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.805555555555557\n",
      "    ram_util_percent: 19.424999999999997\n",
      "  pid: 151\n",
      "  policy_reward_max:\n",
      "    policy_0: 78.0\n",
      "    policy_1: 87.0\n",
      "    policy_2: 81.0\n",
      "    policy_3: 99.0\n",
      "    policy_4: 93.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 10.749425287356322\n",
      "    policy_1: 9.135632183908045\n",
      "    policy_2: 13.565517241379311\n",
      "    policy_3: 12.455172413793104\n",
      "    policy_4: 12.202298850574712\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 1.3674668855329815\n",
      "    mean_inference_ms: 20.86548365695659\n",
      "    mean_processing_ms: 2.2451338667705567\n",
      "  time_since_restore: 290.99815917015076\n",
      "  time_this_iter_s: 26.11240553855896\n",
      "  time_total_s: 290.99815917015076\n",
      "  timestamp: 1585610608\n",
      "  timesteps_since_restore: 115200\n",
      "  timesteps_this_iter: 11520\n",
      "  timesteps_total: 115200\n",
      "  training_iteration: 10\n",
      "  trial_id: adfaf3f0\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.7/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc             |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-----------------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | RUNNING  | 10.0.203.14:151 |   58.108 |          290.998 | 115200 |     10 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-----------------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 11.3/62.1 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 0/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 TERMINATED)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+------------+-------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status     | loc   |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+------------+-------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_adfaf3f0 | TERMINATED |       |   58.108 |          290.998 | 115200 |     10 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+------------+-------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mSaved model configuration.\u001b[0m\n",
      "\u001b[34m#033[2m#033[33m(pid=raylet)#033[0m E0330 23:23:29.130247   111 process.cc:283] Failed to kill processs 145 with error system:3: No such process\u001b[0m\n",
      "\u001b[34mSaved the checkpoint file /opt/ml/output/intermediate/training/PPO_MultiAgentBattlesnake-v1_adfaf3f0_0_2020-03-30_23-17-528izubhx5/checkpoint_10/checkpoint-10 as /opt/ml/model/checkpoint\u001b[0m\n",
      "\u001b[34mSaved the checkpoint file /opt/ml/output/intermediate/training/PPO_MultiAgentBattlesnake-v1_adfaf3f0_0_2020-03-30_23-17-528izubhx5/checkpoint_10/checkpoint-10.tune_metadata as /opt/ml/model/checkpoint.tune_metadata\u001b[0m\n",
      "\u001b[34m2020-03-30 23:23:34,115#011INFO trainer.py:420 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\u001b[0m\n",
      "\u001b[34m2020-03-30 23:23:34,120#011INFO trainer.py:580 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=5395)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=5395)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=5395)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=5395)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=5395)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=5395)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=5395)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=5395)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=5395)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=5395)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m2020-03-30 23:24:03,110#011INFO trainable.py:178 -- _setup took 28.992 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\u001b[0m\n",
      "\u001b[34m2020-03-30 23:24:04,863#011WARNING trainable.py:210 -- Getting current IP.\u001b[0m\n",
      "\u001b[34m2020-03-30 23:24:04,864#011INFO trainable.py:416 -- Restored on 10.0.203.14 from checkpoint: /opt/ml/model/checkpoint\u001b[0m\n",
      "\u001b[34m2020-03-30 23:24:04,864#011INFO trainable.py:423 -- Current state after restoring: {'_iteration': 10, '_timesteps_total': 115200, '_time_total': 290.99815917015076, '_episodes_total': 13122}\u001b[0m\n",
      "\u001b[34mSaved TensorFlow serving model!\n",
      "\u001b[0m\n",
      "\u001b[34m2020-03-30 23:24:09,873 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-03-30 23:24:23 Uploading - Uploading generated training model\n",
      "2020-03-30 23:24:23 Completed - Training job completed\n",
      "Training seconds: 465\n",
      "Billable seconds: 465\n",
      "Training job: battlesnake-rllib-ppo-2020-03-30-23-14-59-441\n",
      "CPU times: user 1.22 s, sys: 75.3 ms, total: 1.29 s\n",
      "Wall time: 9min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define and execute our training job\n",
    "# Adjust hyperparameters and train_instance_count accordingly\n",
    "\n",
    "metric_definitions = RLEstimator.default_metric_definitions(RLToolkit.RAY)\n",
    "    \n",
    "estimator = RLEstimator(entry_point=\"train-mabs.py\",\n",
    "                        source_dir='src',\n",
    "                        dependencies=[\"common/sagemaker_rl\", \"common/battlesnake_gym\", \"checkpoints\"],\n",
    "                        image_name=image_name,\n",
    "                        role=role,\n",
    "                        train_instance_type=instance_type,\n",
    "                        train_instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        base_job_name=job_name_prefix,\n",
    "                        metric_definitions=metric_definitions,\n",
    "                        hyperparameters={\n",
    "                            # See train-mabs.py to add additional hyperparameters\n",
    "                            # Also see ray_launcher.py for the rl.training.* hyperparameters\n",
    "                            #\n",
    "                            # number of training iterations\n",
    "                            \"num_iters\": 10,\n",
    "                            # number of snakes in the gym\n",
    "                            \"num_agents\": 5,\n",
    "                            # dimension of the gym. changing this could require changes to CNN kernels\n",
    "                            # in cnn_ft.py\n",
    "                            \"map_height\": 21,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "estimator.fit()\n",
    "\n",
    "job_name = estimator.latest_training_job.job_name\n",
    "print(\"Training job: %s\" % job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-412868550678/battlesnake-rllib-ppo-2020-03-30-23-14-59-441/output/model.tar.gz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where is the model stored in S3?\n",
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "#model_data = \"s3://sagemaker-us-west-2-412868550678/battlesnake-rllib-ppo-2020-03-30-20-06-31-079/output/model.tar.gz\"\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data=estimator.model_data,\n",
    "              role=role,\n",
    "              entry_point=\"inference.py\",\n",
    "              source_dir='inference',\n",
    "              framework_version='2.1.0',\n",
    "             )\n",
    "\n",
    "if local_mode:\n",
    "    inf_instance_type = 'local'\n",
    "else:\n",
    "    inf_instance_type = \"ml.t2.medium\"\n",
    "\n",
    "# Deploy an inference endpoint\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=inf_instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw inference results:\n",
      "   action_logp :  [0.0]\n",
      "   action_prob :  [1.0]\n",
      "   actions :  [0]\n",
      "   behaviour_logits :  [[0.0550115407, -0.031956654, -0.0453675911, 0.0185272116]]\n",
      "   heuristisc_action :  0\n",
      "   vf_preds :  [-0.753036618]\n",
      "\n",
      "Our model predicts that the next action to take is: action 0\n",
      "\n",
      "Inference took 706.75 ms\n"
     ]
    }
   ],
   "source": [
    "# Spoof an observation from a Battlesnake environment, and get the predicted action from the model\n",
    "#\n",
    "# This example is using single observation for a 5-agent environment with an 11x11 map\n",
    "# The last axis is 12 because the current MultiAgentEnv is concatenating 2 frames\n",
    "#   5 agent maps + 1 food map = 6 maps total    6 maps * 2 frames = 12\n",
    "#\n",
    "# Note: this prediction is for the first policy in the environment \"policy_0\"\n",
    "#   We need to fix this to export the 'best' policy, all policies, etc.\n",
    "#   Also - the agent's policy # and position within the observation *does* currently matter.\n",
    "#   For example, if we export policy_4 for inference, we need to ensure that the agent's current\n",
    "#   snake representation (during inference) is located within index 4 of the observations (food is index 0)\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "health_dict = {0: 50, 1: 50}\n",
    "json = {\"turn\": 4,\n",
    "        \"board\": {\n",
    "                \"height\": 15,\n",
    "                \"width\": 15,\n",
    "                \"food\": [],\n",
    "                \"snakes\": []\n",
    "                },\n",
    "            \"you\": {\n",
    "                \"id\": \"snake-id-string\",\n",
    "                \"name\": \"Sneky Snek\",\n",
    "                \"health\": 90,\n",
    "                \"body\": [{\"x\": 1, \"y\": 3}]\n",
    "                }\n",
    "            }\n",
    "\n",
    "fake_obs = np.zeros(shape=(1,11,11,12), dtype=np.float32).tolist()\n",
    "\n",
    "test_data = {\"inputs\": { 'observations': fake_obs,\n",
    "                        'prev_action': -1,\n",
    "                        'is_training': False,\n",
    "                        'prev_reward': -1,\n",
    "                        'seq_lens': -1\n",
    "                       },\n",
    "             \"all_health\": health_dict,\n",
    "             \"json\": json\n",
    "            }\n",
    "before = time()\n",
    "result = predictor.predict(test_data)\n",
    "elapsed = time() - before\n",
    "\n",
    "print(\"Raw inference results:\")\n",
    "for key in sorted(result['outputs'].keys()):\n",
    "    print(\"  \", key, \": \", result['outputs'][key])\n",
    "\n",
    "print()\n",
    "print(\"Our model predicts that the next action to take is: action\", result['outputs']['actions'][0])\n",
    "print()\n",
    "print(\"Inference took %.2f ms\" % (elapsed*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run to delete the endpoint\n",
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
