{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook outlines the steps involved in building and deploying a Battlesnake model using Ray RLlib and TensorFlow on Amazon SageMaker.\n",
    "\n",
    "Library versions currently in use:  TensorFlow 2.1, Ray RLlib 0.8.2\n",
    "\n",
    "The model is first trained using multi-agent PPO, and then deployed to a managed _TensorFlow Serving_ SageMaker endpoint that can be used for inference.\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Note:** This is a work-in-progress...\n",
    "\n",
    "### Comments and Known Issues\n",
    "\n",
    "* `cnn_tf.py` currently contains default CNN filters for map sizes ranging 7x7 to 21x21. These default filter sizes can be overriden via the 'conv_filters' config parameter.\n",
    "* The current MultiAgentBattlesnake environment uses 2 frames for each observation. If you only want to use one frame, you'll need to adjust the observation code in `ma_battlesnake.py` accordingly\n",
    "* The original TF model export code in `ray_launcher.py` did not work for TF2.1.\n",
    "  * I switched over to RLlib's export_model() method, which seems to be working here\n",
    "* I have not yet tested RLlib's built-in `{'use_lstm': True}` model parameter, which wraps the CNN in an LSTM. This was working for local training/inference but has not been tested with the SageMaker inference endpoint, yet\n",
    "* Regardless of the number of snakes in the gym, or which policy is 'best', only policy_0 is currently exported as a TF model. Refer to `common/sagemaker_rl/tf_serving_utils.py` and see the comment in the inference section, below\n",
    "* The Ray dashboard fails to start (errors during training) but does not abort the training job\n",
    "* There are many warnings during training - most appear to be benign, but are annoying\n",
    "* Both local-mode and SageMaker-based training and inference have been tested, and appear to be working\n",
    "    * local-mode inference might generate some warnings, but seems to work regardless\n",
    "* GPU training has been tested\n",
    "* GPU inference has not been tested\n",
    "* Single-instance training has been tested. Distributed multi-instance RLlib training has not yet been tested.\n",
    "* Although the hosted model is able to provide predictions, I haven't yet verified that the predictions are correct or useful.\n",
    "* The default hyperparameters are unlikely to generate an impressive model. Modify the hyperparameters and rewards if you are hoping to see something cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket path: s3://sagemaker-us-west-2-412868550678/\n"
     ]
    }
   ],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "s3_bucket = sm_session.default_bucket()\n",
    "\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::412868550678:role/BattlesnakeEnvironment-jo-NotebookInstanceExecutio-1ESEZD1FEJJ5V\n"
     ]
    }
   ],
   "source": [
    "job_name_prefix = 'battlesnake-rllib-ppo'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change local_mode to True if you want to do local training within this Notebook instance\n",
    "# Otherwise, we'll spin-up a SageMaker training instance to handle the training\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = 'local'\n",
    "else:\n",
    "    instance_type = \"ml.m5.4xlarge\"\n",
    "    \n",
    "# If training locally, do some Docker housekeeping..\n",
    "if local_mode:\n",
    "    !/bin/bash ./common/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the new TF v2.1 / Ray RLlib 0.8.2 container\n",
    "#    Adjust 'cpu' or 'gpu' in the image name, as required\n",
    "image_name = '462105765813.dkr.ecr.us-west-2.amazonaws.com/sagemaker-rl-ray-container:ray-0.8.2-tf-cpu-py36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-02 22:28:44 Starting - Starting the training job...\n",
      "2020-04-02 22:28:46 Starting - Launching requested ML instances......\n",
      "2020-04-02 22:29:53 Starting - Preparing the instances for training...\n",
      "2020-04-02 22:30:33 Downloading - Downloading input data\n",
      "2020-04-02 22:30:33 Training - Downloading the training image......\n",
      "2020-04-02 22:31:37 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-04-02 22:31:40,191 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-04-02 22:31:40,197 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-02 22:31:40,308 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-02 22:31:40,324 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-02 22:31:40,338 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-02 22:31:40,348 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator\": \"RLEstimator\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"num_iters\": 10,\n",
      "        \"num_agents\": 5,\n",
      "        \"map_height\": 15,\n",
      "        \"observation_type\": \"flat-51s\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"battlesnake-rllib-ppo-2020-04-02-22-28-43-744\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-412868550678/battlesnake-rllib-ppo-2020-04-02-22-28-43-744/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train-mabs\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train-mabs.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"map_height\":15,\"num_agents\":5,\"num_iters\":10,\"observation_type\":\"flat-51s\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train-mabs.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train-mabs\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-412868550678/battlesnake-rllib-ppo-2020-04-02-22-28-43-744/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"map_height\":15,\"num_agents\":5,\"num_iters\":10,\"observation_type\":\"flat-51s\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"battlesnake-rllib-ppo-2020-04-02-22-28-43-744\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-412868550678/battlesnake-rllib-ppo-2020-04-02-22-28-43-744/source/sourcedir.tar.gz\",\"module_name\":\"train-mabs\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-mabs.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--map_height\",\"15\",\"--num_agents\",\"5\",\"--num_iters\",\"10\",\"--observation_type\",\"flat-51s\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ITERS=10\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_AGENTS=5\u001b[0m\n",
      "\u001b[34mSM_HP_MAP_HEIGHT=15\u001b[0m\n",
      "\u001b[34mSM_HP_OBSERVATION_TYPE=flat-51s\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train-mabs.py --map_height 15 --num_agents 5 --num_iters 10 --observation_type flat-51s\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-04-02 22:31:43,438#011INFO resource_spec.py:212 -- Starting Ray with 33.59 GiB memory available for workers and up to 16.81 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\u001b[0m\n",
      "\u001b[34m2020-04-02 22:31:43,848#011INFO services.py:1078 -- View the Ray dashboard at #033[1m#033[32mlocalhost:8265#033[39m#033[22m\u001b[0m\n",
      "\u001b[34mNo checkpoint path specified. Training from scratch.\u001b[0m\n",
      "\u001b[34mImportant! Ray with version <=7.2 may report \"Did not find checkpoint file\" even if the experiment is actually restored successfully. If restoration is expected, please check \"training_iteration\" in the experiment info to confirm.\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 2.9/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc   |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+-------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  |       |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+-------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-04-02 22:31:45,051#011WARNING worker.py:1058 -- The dashboard on node ip-10-0-156-121.us-west-2.compute.internal failed with the following error:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1062, in create_server\n",
      "    sock.bind(sa)\u001b[0m\n",
      "\u001b[34mOSError: [Errno 99] Cannot assign requested address\n",
      "\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ray/dashboard/dashboard.py\", line 920, in <module>\n",
      "    dashboard.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ray/dashboard/dashboard.py\", line 368, in run\n",
      "    aiohttp.web.run_app(self.app, host=self.host, port=self.port)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/web.py\", line 433, in run_app\n",
      "    reuse_port=reuse_port))\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 484, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/web.py\", line 359, in _run_app\n",
      "    await site.start()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/web_runner.py\", line 104, in start\n",
      "    reuse_port=self._reuse_port)\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1066, in create_server\n",
      "    % (sa, err.strerror.lower()))\u001b[0m\n",
      "\u001b[34mOSError: [Errno 99] error while attempting to bind on address ('::1', 8265, 0, 0): cannot assign requested address\n",
      "\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m 2020-04-02 22:31:46,800#011INFO trainer.py:420 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m 2020-04-02 22:31:46,811#011INFO trainer.py:580 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=141)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=150)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=137)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=138)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=140)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=149)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=151)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=144)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=143)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=139)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=152)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=147)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=146)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=142)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=145)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=148)#033[0m 2020-04-02 22:32:26,444#011INFO trainable.py:178 -- _setup took 39.644 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_bb186570:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-04-02_22-34-52\n",
      "  done: false\n",
      "  episode_len_mean: 4.862295081967213\n",
      "  episode_reward_max: 36.0\n",
      "  episode_reward_mean: -0.6102295081967213\n",
      "  episode_reward_min: -15.0\n",
      "  episodes_this_iter: 7625\n",
      "  episodes_total: 7625\n",
      "  experiment_id: 168e0be706f34592853538e21c1d9ff3\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-156-121.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 72492.306\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3735419511795044\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01232314296066761\n",
      "        policy_loss: -0.025682685896754265\n",
      "        total_loss: 2.8367080688476562\n",
      "        vf_explained_var: 0.10229255259037018\n",
      "        vf_loss: 2.859926462173462\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.374254584312439\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011791194789111614\n",
      "        policy_loss: -0.023358438163995743\n",
      "        total_loss: 2.894815444946289\n",
      "        vf_explained_var: 0.09224025160074234\n",
      "        vf_loss: 2.915815830230713\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3742207288742065\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011654471047222614\n",
      "        policy_loss: -0.023304926231503487\n",
      "        total_loss: 2.958669900894165\n",
      "        vf_explained_var: 0.08616354316473007\n",
      "        vf_loss: 2.9796438217163086\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3735378980636597\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012538833543658257\n",
      "        policy_loss: -0.024949222803115845\n",
      "        total_loss: 2.908405065536499\n",
      "        vf_explained_var: 0.1065983921289444\n",
      "        vf_loss: 2.9308464527130127\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3723667860031128\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013015780597925186\n",
      "        policy_loss: -0.026403112336993217\n",
      "        total_loss: 3.0624821186065674\n",
      "        vf_explained_var: 0.06401707231998444\n",
      "        vf_loss: 3.086282253265381\n",
      "    load_time_ms: 5201.5\n",
      "    num_steps_sampled: 37075\n",
      "    num_steps_trained: 36864\n",
      "    sample_time_ms: 40793.505\n",
      "    update_time_ms: 23194.357\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.156.121\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.201058201058203\n",
      "    ram_util_percent: 30.232804232804234\n",
      "  pid: 148\n",
      "  policy_reward_max:\n",
      "    policy_0: 18.0\n",
      "    policy_1: 17.0\n",
      "    policy_2: 16.0\n",
      "    policy_3: 19.0\n",
      "    policy_4: 22.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: -0.15855737704918033\n",
      "    policy_1: -0.17521311475409837\n",
      "    policy_2: -0.08104918032786886\n",
      "    policy_3: -0.14137704918032787\n",
      "    policy_4: -0.054032786885245904\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.1335586362116707\n",
      "    mean_inference_ms: 49.955242564538686\n",
      "    mean_processing_ms: 5.647863595992147\n",
      "  time_since_restore: 143.55149149894714\n",
      "  time_this_iter_s: 143.55149149894714\n",
      "  time_total_s: 143.55149149894714\n",
      "  timestamp: 1585866892\n",
      "  timesteps_since_restore: 37075\n",
      "  timesteps_this_iter: 37075\n",
      "  timesteps_total: 37075\n",
      "  training_iteration: 1\n",
      "  trial_id: bb186570\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 20.8/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+-------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc              |   reward |   total time (s) |    ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+------------------+----------+------------------+-------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  | 10.0.156.121:148 | -0.61023 |          143.551 | 37075 |      1 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+-------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_bb186570:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-04-02_22-36-38\n",
      "  done: false\n",
      "  episode_len_mean: 5.083904579106115\n",
      "  episode_reward_max: 33.0\n",
      "  episode_reward_mean: -0.03290375651220181\n",
      "  episode_reward_min: -15.0\n",
      "  episodes_this_iter: 7294\n",
      "  episodes_total: 14919\n",
      "  experiment_id: 168e0be706f34592853538e21c1d9ff3\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-156-121.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 68308.563\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3386977910995483\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018664784729480743\n",
      "        policy_loss: -0.04667169973254204\n",
      "        total_loss: 2.830129861831665\n",
      "        vf_explained_var: 0.24437379837036133\n",
      "        vf_loss: 2.8730685710906982\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3431353569030762\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017329027876257896\n",
      "        policy_loss: -0.043760884553194046\n",
      "        total_loss: 2.7216639518737793\n",
      "        vf_explained_var: 0.2504380941390991\n",
      "        vf_loss: 2.7619590759277344\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.343325138092041\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01820005290210247\n",
      "        policy_loss: -0.04303911700844765\n",
      "        total_loss: 2.8573923110961914\n",
      "        vf_explained_var: 0.2546205520629883\n",
      "        vf_loss: 2.8967909812927246\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3417288064956665\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017741532996296883\n",
      "        policy_loss: -0.04210983216762543\n",
      "        total_loss: 2.8734467029571533\n",
      "        vf_explained_var: 0.24443303048610687\n",
      "        vf_loss: 2.912008285522461\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.3375104665756226\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017974816262722015\n",
      "        policy_loss: -0.04517068341374397\n",
      "        total_loss: 2.914987564086914\n",
      "        vf_explained_var: 0.23400923609733582\n",
      "        vf_loss: 2.9565634727478027\n",
      "    load_time_ms: 3863.815\n",
      "    num_steps_sampled: 74157\n",
      "    num_steps_trained: 73728\n",
      "    sample_time_ms: 39847.689\n",
      "    update_time_ms: 11613.313\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 10.0.156.121\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.366929133858267\n",
      "    ram_util_percent: 37.576377952755884\n",
      "  pid: 148\n",
      "  policy_reward_max:\n",
      "    policy_0: 19.0\n",
      "    policy_1: 17.0\n",
      "    policy_2: 18.0\n",
      "    policy_3: 19.0\n",
      "    policy_4: 17.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: -0.01741157115437346\n",
      "    policy_1: -0.15327666575267343\n",
      "    policy_2: 0.027282698108034\n",
      "    policy_3: 0.046476556073485054\n",
      "    policy_4: 0.06402522621332603\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.131752693659351\n",
      "    mean_inference_ms: 49.51980116612545\n",
      "    mean_processing_ms: 5.587457309090107\n",
      "  time_since_restore: 249.25159692764282\n",
      "  time_this_iter_s: 105.70010542869568\n",
      "  time_total_s: 249.25159692764282\n",
      "  timestamp: 1585866998\n",
      "  timesteps_since_restore: 74157\n",
      "  timesteps_this_iter: 37082\n",
      "  timesteps_total: 74157\n",
      "  training_iteration: 2\n",
      "  trial_id: bb186570\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 20.8/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+------------+------------------+-------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc              |     reward |   total time (s) |    ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+------------------+------------+------------------+-------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  | 10.0.156.121:148 | -0.0329038 |          249.252 | 74157 |      2 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+------------+------------------+-------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_bb186570:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-04-02_22-38-24\n",
      "  done: false\n",
      "  episode_len_mean: 5.718557336621455\n",
      "  episode_reward_max: 44.0\n",
      "  episode_reward_mean: 1.8820900123304563\n",
      "  episode_reward_min: -15.0\n",
      "  episodes_this_iter: 6488\n",
      "  episodes_total: 21407\n",
      "  experiment_id: 168e0be706f34592853538e21c1d9ff3\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-156-121.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 66925.782\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2762891054153442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02323954366147518\n",
      "        policy_loss: -0.06199553981423378\n",
      "        total_loss: 3.5847561359405518\n",
      "        vf_explained_var: 0.27322226762771606\n",
      "        vf_loss: 3.642103433609009\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.282589077949524\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02367391064763069\n",
      "        policy_loss: -0.05873982608318329\n",
      "        total_loss: 3.3812971115112305\n",
      "        vf_explained_var: 0.2696860432624817\n",
      "        vf_loss: 3.435302257537842\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2819300889968872\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024350153282284737\n",
      "        policy_loss: -0.06195640563964844\n",
      "        total_loss: 3.5168986320495605\n",
      "        vf_explained_var: 0.27319514751434326\n",
      "        vf_loss: 3.5739848613739014\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2718769311904907\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024119675159454346\n",
      "        policy_loss: -0.06146608293056488\n",
      "        total_loss: 3.535978317260742\n",
      "        vf_explained_var: 0.275248646736145\n",
      "        vf_loss: 3.592620372772217\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2751665115356445\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024736210703849792\n",
      "        policy_loss: -0.061013564467430115\n",
      "        total_loss: 3.533094644546509\n",
      "        vf_explained_var: 0.2699517607688904\n",
      "        vf_loss: 3.589160919189453\n",
      "    load_time_ms: 3447.487\n",
      "    num_steps_sampled: 111259\n",
      "    num_steps_trained: 110592\n",
      "    sample_time_ms: 39354.161\n",
      "    update_time_ms: 7752.434\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.0.156.121\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.055118110236222\n",
      "    ram_util_percent: 37.705511811023634\n",
      "  pid: 148\n",
      "  policy_reward_max:\n",
      "    policy_0: 25.0\n",
      "    policy_1: 20.0\n",
      "    policy_2: 18.0\n",
      "    policy_3: 21.0\n",
      "    policy_4: 25.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 0.4250924784217016\n",
      "    policy_1: 0.20545622688039458\n",
      "    policy_2: 0.39519112207151663\n",
      "    policy_3: 0.40135635018495686\n",
      "    policy_4: 0.45499383477188654\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.1292733474759475\n",
      "    mean_inference_ms: 49.26346933296626\n",
      "    mean_processing_ms: 5.436331840381291\n",
      "  time_since_restore: 354.5273084640503\n",
      "  time_this_iter_s: 105.27571153640747\n",
      "  time_total_s: 354.5273084640503\n",
      "  timestamp: 1585867104\n",
      "  timesteps_since_restore: 111259\n",
      "  timesteps_this_iter: 37102\n",
      "  timesteps_total: 111259\n",
      "  training_iteration: 3\n",
      "  trial_id: bb186570\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 20.8/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc              |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+------------------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  | 10.0.156.121:148 |  1.88209 |          354.527 | 111259 |      3 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_bb186570:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-04-02_22-40-09\n",
      "  done: false\n",
      "  episode_len_mean: 7.235408560311284\n",
      "  episode_reward_max: 50.0\n",
      "  episode_reward_mean: 6.458365758754864\n",
      "  episode_reward_min: -15.0\n",
      "  episodes_this_iter: 5140\n",
      "  episodes_total: 26547\n",
      "  experiment_id: 168e0be706f34592853538e21c1d9ff3\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-156-121.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 66182.257\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1969773769378662\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0240835789591074\n",
      "        policy_loss: -0.0684526115655899\n",
      "        total_loss: 4.898645401000977\n",
      "        vf_explained_var: 0.32212620973587036\n",
      "        vf_loss: 4.959873676300049\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2181215286254883\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02366642653942108\n",
      "        policy_loss: -0.0661095604300499\n",
      "        total_loss: 4.2442426681518555\n",
      "        vf_explained_var: 0.31177404522895813\n",
      "        vf_loss: 4.303252220153809\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.206559658050537\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0238493699580431\n",
      "        policy_loss: -0.06278306990861893\n",
      "        total_loss: 4.872852802276611\n",
      "        vf_explained_var: 0.31247690320014954\n",
      "        vf_loss: 4.928481101989746\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.19066321849823\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02334739826619625\n",
      "        policy_loss: -0.06426654756069183\n",
      "        total_loss: 4.728401184082031\n",
      "        vf_explained_var: 0.3284463584423065\n",
      "        vf_loss: 4.7856645584106445\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.2054924964904785\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024112524464726448\n",
      "        policy_loss: -0.06632060557603836\n",
      "        total_loss: 4.7486348152160645\n",
      "        vf_explained_var: 0.31475040316581726\n",
      "        vf_loss: 4.8077216148376465\n",
      "    load_time_ms: 3212.887\n",
      "    num_steps_sampled: 148449\n",
      "    num_steps_trained: 147456\n",
      "    sample_time_ms: 39072.241\n",
      "    update_time_ms: 5820.934\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 10.0.156.121\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.751587301587307\n",
      "    ram_util_percent: 37.72539682539684\n",
      "  pid: 148\n",
      "  policy_reward_max:\n",
      "    policy_0: 23.0\n",
      "    policy_1: 25.0\n",
      "    policy_2: 28.0\n",
      "    policy_3: 24.0\n",
      "    policy_4: 27.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 1.5319066147859923\n",
      "    policy_1: 0.9607003891050584\n",
      "    policy_2: 1.2852140077821013\n",
      "    policy_3: 1.3527237354085604\n",
      "    policy_4: 1.3278210116731517\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.143336197634755\n",
      "    mean_inference_ms: 49.18643243022075\n",
      "    mean_processing_ms: 5.209514501783846\n",
      "  time_since_restore: 459.4017667770386\n",
      "  time_this_iter_s: 104.87445831298828\n",
      "  time_total_s: 459.4017667770386\n",
      "  timestamp: 1585867209\n",
      "  timesteps_since_restore: 148449\n",
      "  timesteps_this_iter: 37190\n",
      "  timesteps_total: 148449\n",
      "  training_iteration: 4\n",
      "  trial_id: bb186570\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 20.9/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc              |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+------------------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  | 10.0.156.121:148 |  6.45837 |          459.402 | 148449 |      4 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_bb186570:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-04-02_22-41-54\n",
      "  done: false\n",
      "  episode_len_mean: 9.642410015649451\n",
      "  episode_reward_max: 83.0\n",
      "  episode_reward_mean: 13.87663015127804\n",
      "  episode_reward_min: -15.0\n",
      "  episodes_this_iter: 3834\n",
      "  episodes_total: 30381\n",
      "  experiment_id: 168e0be706f34592853538e21c1d9ff3\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-156-121.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 65814.668\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.128438949584961\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020924707874655724\n",
      "        policy_loss: -0.05736229941248894\n",
      "        total_loss: 6.857275009155273\n",
      "        vf_explained_var: 0.38097134232521057\n",
      "        vf_loss: 6.905221462249756\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1443767547607422\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020262621343135834\n",
      "        policy_loss: -0.059846680611371994\n",
      "        total_loss: 6.086008548736572\n",
      "        vf_explained_var: 0.38250744342803955\n",
      "        vf_loss: 6.136737823486328\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1522326469421387\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01895718090236187\n",
      "        policy_loss: -0.0588080957531929\n",
      "        total_loss: 6.230227470397949\n",
      "        vf_explained_var: 0.3780069947242737\n",
      "        vf_loss: 6.2805047035217285\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1210756301879883\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020750103518366814\n",
      "        policy_loss: -0.05763128027319908\n",
      "        total_loss: 6.462015151977539\n",
      "        vf_explained_var: 0.3984309434890747\n",
      "        vf_loss: 6.510308742523193\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.1248164176940918\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01918026991188526\n",
      "        policy_loss: -0.06197834759950638\n",
      "        total_loss: 6.7815704345703125\n",
      "        vf_explained_var: 0.37622058391571045\n",
      "        vf_loss: 6.834918022155762\n",
      "    load_time_ms: 3056.217\n",
      "    num_steps_sampled: 185418\n",
      "    num_steps_trained: 184320\n",
      "    sample_time_ms: 38800.311\n",
      "    update_time_ms: 4662.108\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.0.156.121\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.1552\n",
      "    ram_util_percent: 37.832000000000015\n",
      "  pid: 148\n",
      "  policy_reward_max:\n",
      "    policy_0: 35.0\n",
      "    policy_1: 28.0\n",
      "    policy_2: 38.0\n",
      "    policy_3: 33.0\n",
      "    policy_4: 42.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 2.979134063641106\n",
      "    policy_1: 2.584246218049035\n",
      "    policy_2: 2.3753260302556076\n",
      "    policy_3: 2.9295774647887325\n",
      "    policy_4: 3.0083463745435575\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.148405115271197\n",
      "    mean_inference_ms: 49.15073270642823\n",
      "    mean_processing_ms: 4.950217740010682\n",
      "  time_since_restore: 564.1933627128601\n",
      "  time_this_iter_s: 104.79159593582153\n",
      "  time_total_s: 564.1933627128601\n",
      "  timestamp: 1585867314\n",
      "  timesteps_since_restore: 185418\n",
      "  timesteps_this_iter: 36969\n",
      "  timesteps_total: 185418\n",
      "  training_iteration: 5\n",
      "  trial_id: bb186570\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 20.9/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc              |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+------------------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  | 10.0.156.121:148 |  13.8766 |          564.193 | 185418 |      5 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_bb186570:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-04-02_22-43-39\n",
      "  done: false\n",
      "  episode_len_mean: 12.99475890985325\n",
      "  episode_reward_max: 106.0\n",
      "  episode_reward_mean: 24.038085255066388\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 2862\n",
      "  episodes_total: 33243\n",
      "  experiment_id: 168e0be706f34592853538e21c1d9ff3\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-156-121.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 65561.674\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0827012062072754\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01522087026387453\n",
      "        policy_loss: -0.04950869083404541\n",
      "        total_loss: 9.278837203979492\n",
      "        vf_explained_var: 0.45240700244903564\n",
      "        vf_loss: 9.318071365356445\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0923042297363281\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01448640413582325\n",
      "        policy_loss: -0.05386540666222572\n",
      "        total_loss: 8.256040573120117\n",
      "        vf_explained_var: 0.45799314975738525\n",
      "        vf_loss: 8.300127029418945\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0862312316894531\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017673227936029434\n",
      "        policy_loss: -0.04931245371699333\n",
      "        total_loss: 8.814769744873047\n",
      "        vf_explained_var: 0.44547075033187866\n",
      "        vf_loss: 8.856128692626953\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0793603658676147\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014620746485888958\n",
      "        policy_loss: -0.05179724097251892\n",
      "        total_loss: 9.069961547851562\n",
      "        vf_explained_var: 0.456468790769577\n",
      "        vf_loss: 9.111889839172363\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0671616792678833\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019253211095929146\n",
      "        policy_loss: -0.05094191059470177\n",
      "        total_loss: 9.08260726928711\n",
      "        vf_explained_var: 0.4547176957130432\n",
      "        vf_loss: 9.124885559082031\n",
      "    load_time_ms: 2969.979\n",
      "    num_steps_sampled: 222609\n",
      "    num_steps_trained: 221184\n",
      "    sample_time_ms: 38638.81\n",
      "    update_time_ms: 3889.388\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 10.0.156.121\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.964285714285715\n",
      "    ram_util_percent: 37.889682539682525\n",
      "  pid: 148\n",
      "  policy_reward_max:\n",
      "    policy_0: 42.0\n",
      "    policy_1: 39.0\n",
      "    policy_2: 49.0\n",
      "    policy_3: 46.0\n",
      "    policy_4: 38.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 5.13382250174703\n",
      "    policy_1: 4.40041928721174\n",
      "    policy_2: 4.556953179594689\n",
      "    policy_3: 4.846610761705102\n",
      "    policy_4: 5.100279524807827\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.15734537301874\n",
      "    mean_inference_ms: 49.21233503032539\n",
      "    mean_processing_ms: 4.703382268040248\n",
      "  time_since_restore: 668.9631202220917\n",
      "  time_this_iter_s: 104.76975750923157\n",
      "  time_total_s: 668.9631202220917\n",
      "  timestamp: 1585867419\n",
      "  timesteps_since_restore: 222609\n",
      "  timesteps_this_iter: 37191\n",
      "  timesteps_total: 222609\n",
      "  training_iteration: 6\n",
      "  trial_id: bb186570\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 21.0/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc              |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+------------------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  | 10.0.156.121:148 |  24.0381 |          668.963 | 222609 |      6 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_bb186570:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-04-02_22-45-24\n",
      "  done: false\n",
      "  episode_len_mean: 17.46142991533396\n",
      "  episode_reward_max: 141.0\n",
      "  episode_reward_mean: 36.991533396048915\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 2126\n",
      "  episodes_total: 35369\n",
      "  experiment_id: 168e0be706f34592853538e21c1d9ff3\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-156-121.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 65374.9\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.042967438697815\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012933872640132904\n",
      "        policy_loss: -0.04111699387431145\n",
      "        total_loss: 12.881254196166992\n",
      "        vf_explained_var: 0.512548565864563\n",
      "        vf_loss: 12.913640975952148\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0512422323226929\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014464689418673515\n",
      "        policy_loss: -0.04558474197983742\n",
      "        total_loss: 10.656794548034668\n",
      "        vf_explained_var: 0.5334000587463379\n",
      "        vf_loss: 10.69261646270752\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0394997596740723\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015174467116594315\n",
      "        policy_loss: -0.045831918716430664\n",
      "        total_loss: 11.51339340209961\n",
      "        vf_explained_var: 0.5215235948562622\n",
      "        vf_loss: 11.552397727966309\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0329370498657227\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013251008465886116\n",
      "        policy_loss: -0.04355534538626671\n",
      "        total_loss: 11.866771697998047\n",
      "        vf_explained_var: 0.5236918926239014\n",
      "        vf_loss: 11.901382446289062\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.013645052909851\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01645408570766449\n",
      "        policy_loss: -0.04662962257862091\n",
      "        total_loss: 12.806710243225098\n",
      "        vf_explained_var: 0.5074198246002197\n",
      "        vf_loss: 12.845935821533203\n",
      "    load_time_ms: 2920.271\n",
      "    num_steps_sampled: 259732\n",
      "    num_steps_trained: 258048\n",
      "    sample_time_ms: 38562.005\n",
      "    update_time_ms: 3337.534\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 10.0.156.121\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.976190476190478\n",
      "    ram_util_percent: 37.96190476190477\n",
      "  pid: 148\n",
      "  policy_reward_max:\n",
      "    policy_0: 67.0\n",
      "    policy_1: 66.0\n",
      "    policy_2: 60.0\n",
      "    policy_3: 46.0\n",
      "    policy_4: 59.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 7.742238946378175\n",
      "    policy_1: 6.514581373471308\n",
      "    policy_2: 6.586547507055504\n",
      "    policy_3: 7.690498588899342\n",
      "    policy_4: 8.457666980244591\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.167634305941561\n",
      "    mean_inference_ms: 49.35005357590867\n",
      "    mean_processing_ms: 4.483415456029821\n",
      "  time_since_restore: 774.0376446247101\n",
      "  time_this_iter_s: 105.07452440261841\n",
      "  time_total_s: 774.0376446247101\n",
      "  timestamp: 1585867524\n",
      "  timesteps_since_restore: 259732\n",
      "  timesteps_this_iter: 37123\n",
      "  timesteps_total: 259732\n",
      "  training_iteration: 7\n",
      "  trial_id: bb186570\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 21.0/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc              |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+------------------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  | 10.0.156.121:148 |  36.9915 |          774.038 | 259732 |      7 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_bb186570:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-04-02_22-47-09\n",
      "  done: false\n",
      "  episode_len_mean: 23.025465838509316\n",
      "  episode_reward_max: 227.0\n",
      "  episode_reward_mean: 53.06832298136646\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1610\n",
      "  episodes_total: 36979\n",
      "  experiment_id: 168e0be706f34592853538e21c1d9ff3\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-156-121.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 65249.777\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0144115686416626\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015998121351003647\n",
      "        policy_loss: -0.03143148869276047\n",
      "        total_loss: 16.387998580932617\n",
      "        vf_explained_var: 0.5809226036071777\n",
      "        vf_loss: 16.408632278442383\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0157437324523926\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012300748378038406\n",
      "        policy_loss: -0.04162488877773285\n",
      "        total_loss: 13.909213066101074\n",
      "        vf_explained_var: 0.5845916867256165\n",
      "        vf_loss: 13.942534446716309\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.9888907670974731\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015579708851873875\n",
      "        policy_loss: -0.036191556602716446\n",
      "        total_loss: 15.47402286529541\n",
      "        vf_explained_var: 0.5842325091362\n",
      "        vf_loss: 15.50320053100586\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0078530311584473\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013930358923971653\n",
      "        policy_loss: -0.03808846324682236\n",
      "        total_loss: 15.940187454223633\n",
      "        vf_explained_var: 0.5766994953155518\n",
      "        vf_loss: 15.968873977661133\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.9772735238075256\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015171779319643974\n",
      "        policy_loss: -0.04117453843355179\n",
      "        total_loss: 16.451454162597656\n",
      "        vf_explained_var: 0.5755446553230286\n",
      "        vf_loss: 16.485797882080078\n",
      "    load_time_ms: 2868.736\n",
      "    num_steps_sampled: 296803\n",
      "    num_steps_trained: 294912\n",
      "    sample_time_ms: 38446.737\n",
      "    update_time_ms: 2923.793\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 10.0.156.121\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.635999999999996\n",
      "    ram_util_percent: 38.01040000000001\n",
      "  pid: 148\n",
      "  policy_reward_max:\n",
      "    policy_0: 80.0\n",
      "    policy_1: 84.0\n",
      "    policy_2: 77.0\n",
      "    policy_3: 78.0\n",
      "    policy_4: 71.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 10.575155279503106\n",
      "    policy_1: 9.809937888198757\n",
      "    policy_2: 10.441614906832298\n",
      "    policy_3: 10.34223602484472\n",
      "    policy_4: 11.899378881987577\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.172477218016488\n",
      "    mean_inference_ms: 49.4650990555164\n",
      "    mean_processing_ms: 4.293077872782983\n",
      "  time_since_restore: 878.6544723510742\n",
      "  time_this_iter_s: 104.61682772636414\n",
      "  time_total_s: 878.6544723510742\n",
      "  timestamp: 1585867629\n",
      "  timesteps_since_restore: 296803\n",
      "  timesteps_this_iter: 37071\n",
      "  timesteps_total: 296803\n",
      "  training_iteration: 8\n",
      "  trial_id: bb186570\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 21.0/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc              |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+------------------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  | 10.0.156.121:148 |  53.0683 |          878.654 | 296803 |      8 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_bb186570:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-04-02_22-48-54\n",
      "  done: false\n",
      "  episode_len_mean: 30.3417004048583\n",
      "  episode_reward_max: 258.0\n",
      "  episode_reward_mean: 71.86801619433199\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1235\n",
      "  episodes_total: 38214\n",
      "  experiment_id: 168e0be706f34592853538e21c1d9ff3\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-156-121.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 65129.495\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.9874935150146484\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011052430607378483\n",
      "        policy_loss: -0.0331544354557991\n",
      "        total_loss: 19.928762435913086\n",
      "        vf_explained_var: 0.6473837494850159\n",
      "        vf_loss: 19.954456329345703\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 1.0008649826049805\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011831223033368587\n",
      "        policy_loss: -0.035722486674785614\n",
      "        total_loss: 15.994406700134277\n",
      "        vf_explained_var: 0.6563035249710083\n",
      "        vf_loss: 16.022144317626953\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.9556518197059631\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01329305674880743\n",
      "        policy_loss: -0.03660910949110985\n",
      "        total_loss: 19.113971710205078\n",
      "        vf_explained_var: 0.6428760290145874\n",
      "        vf_loss: 19.14459800720215\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.991059422492981\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011520626954734325\n",
      "        policy_loss: -0.036030855029821396\n",
      "        total_loss: 19.94363021850586\n",
      "        vf_explained_var: 0.6417912244796753\n",
      "        vf_loss: 19.971885681152344\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.9385831356048584\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015439284965395927\n",
      "        policy_loss: -0.03381764143705368\n",
      "        total_loss: 21.362361907958984\n",
      "        vf_explained_var: 0.6263332962989807\n",
      "        vf_loss: 21.389230728149414\n",
      "    load_time_ms: 2841.858\n",
      "    num_steps_sampled: 334275\n",
      "    num_steps_trained: 331776\n",
      "    sample_time_ms: 38402.464\n",
      "    update_time_ms: 2602.693\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 10.0.156.121\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.6408\n",
      "    ram_util_percent: 38.124\n",
      "  pid: 148\n",
      "  policy_reward_max:\n",
      "    policy_0: 119.0\n",
      "    policy_1: 102.0\n",
      "    policy_2: 91.0\n",
      "    policy_3: 96.0\n",
      "    policy_4: 126.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 14.327935222672064\n",
      "    policy_1: 11.808097165991903\n",
      "    policy_2: 14.25991902834008\n",
      "    policy_3: 14.54331983805668\n",
      "    policy_4: 16.928744939271255\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.1625386287018795\n",
      "    mean_inference_ms: 49.52086173807981\n",
      "    mean_processing_ms: 4.119514769768328\n",
      "  time_since_restore: 983.5966889858246\n",
      "  time_this_iter_s: 104.94221663475037\n",
      "  time_total_s: 983.5966889858246\n",
      "  timestamp: 1585867734\n",
      "  timesteps_since_restore: 334275\n",
      "  timesteps_this_iter: 37472\n",
      "  timesteps_total: 334275\n",
      "  training_iteration: 9\n",
      "  trial_id: bb186570\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 21.1/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc              |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+------------------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  | 10.0.156.121:148 |   71.868 |          983.597 | 334275 |      9 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for PPO_MultiAgentBattlesnake-v1_bb186570:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-04-02_22-50-40\n",
      "  done: true\n",
      "  episode_len_mean: 38.35420944558521\n",
      "  episode_reward_max: 274.0\n",
      "  episode_reward_mean: 93.90451745379877\n",
      "  episode_reward_min: -4.0\n",
      "  episodes_this_iter: 974\n",
      "  episodes_total: 39188\n",
      "  experiment_id: 168e0be706f34592853538e21c1d9ff3\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-156-121.us-west-2.compute.internal\n",
      "  info:\n",
      "    grad_time_ms: 65084.157\n",
      "    learner:\n",
      "      policy_0:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.9676641821861267\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010682052932679653\n",
      "        policy_loss: -0.027549616992473602\n",
      "        total_loss: 24.655261993408203\n",
      "        vf_explained_var: 0.7034769058227539\n",
      "        vf_loss: 24.675601959228516\n",
      "      policy_1:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.979253888130188\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01231842115521431\n",
      "        policy_loss: -0.03258819878101349\n",
      "        total_loss: 20.31200408935547\n",
      "        vf_explained_var: 0.6953384876251221\n",
      "        vf_loss: 20.336275100708008\n",
      "      policy_2:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.9360900521278381\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014332852326333523\n",
      "        policy_loss: -0.03228508308529854\n",
      "        total_loss: 23.97975730895996\n",
      "        vf_explained_var: 0.6968472003936768\n",
      "        vf_loss: 24.005590438842773\n",
      "      policy_3:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.9505085349082947\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010007984936237335\n",
      "        policy_loss: -0.033416472375392914\n",
      "        total_loss: 26.091537475585938\n",
      "        vf_explained_var: 0.6848456859588623\n",
      "        vf_loss: 26.11819839477539\n",
      "      policy_4:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        entropy: 0.9082825779914856\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014829995110630989\n",
      "        policy_loss: -0.028544966131448746\n",
      "        total_loss: 26.188562393188477\n",
      "        vf_explained_var: 0.6803386211395264\n",
      "        vf_loss: 26.21043586730957\n",
      "    load_time_ms: 2823.062\n",
      "    num_steps_sampled: 371632\n",
      "    num_steps_trained: 368640\n",
      "    sample_time_ms: 38396.41\n",
      "    update_time_ms: 2345.007\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.0.156.121\n",
      "  num_healthy_workers: 15\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.648412698412706\n",
      "    ram_util_percent: 38.149206349206345\n",
      "  pid: 148\n",
      "  policy_reward_max:\n",
      "    policy_0: 115.0\n",
      "    policy_1: 110.0\n",
      "    policy_2: 103.0\n",
      "    policy_3: 110.0\n",
      "    policy_4: 107.0\n",
      "  policy_reward_mean:\n",
      "    policy_0: 18.135523613963038\n",
      "    policy_1: 15.695071868583161\n",
      "    policy_2: 18.260780287474333\n",
      "    policy_3: 19.5523613963039\n",
      "    policy_4: 22.260780287474333\n",
      "  policy_reward_min:\n",
      "    policy_0: -3.0\n",
      "    policy_1: -3.0\n",
      "    policy_2: -3.0\n",
      "    policy_3: -3.0\n",
      "    policy_4: -3.0\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.160502644374622\n",
      "    mean_inference_ms: 49.57759418802265\n",
      "    mean_processing_ms: 3.9776198713523607\n",
      "  time_since_restore: 1089.358297586441\n",
      "  time_this_iter_s: 105.76160860061646\n",
      "  time_total_s: 1089.358297586441\n",
      "  timestamp: 1585867840\n",
      "  timesteps_since_restore: 371632\n",
      "  timesteps_this_iter: 37357\n",
      "  timesteps_total: 371632\n",
      "  training_iteration: 10\n",
      "  trial_id: bb186570\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 21.1/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 16/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status   | loc              |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+----------+------------------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | RUNNING  | 10.0.156.121:148 |  93.9045 |          1089.36 | 371632 |     10 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+----------+------------------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 21.1/61.5 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 0/16 CPUs, 0/0 GPUs, 0.0/33.59 GiB heap, 0.0/11.57 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1 (1 TERMINATED)\u001b[0m\n",
      "\u001b[34m+---------------------------------------+------------+-------+----------+------------------+--------+--------+\u001b[0m\n",
      "\u001b[34m| Trial name                            | status     | loc   |   reward |   total time (s) |     ts |   iter |\u001b[0m\n",
      "\u001b[34m|---------------------------------------+------------+-------+----------+------------------+--------+--------|\u001b[0m\n",
      "\u001b[34m| PPO_MultiAgentBattlesnake-v1_bb186570 | TERMINATED |       |  93.9045 |          1089.36 | 371632 |     10 |\u001b[0m\n",
      "\u001b[34m+---------------------------------------+------------+-------+----------+------------------+--------+--------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mSaved model configuration.\u001b[0m\n",
      "\u001b[34mSaved the checkpoint file /opt/ml/output/intermediate/training/PPO_MultiAgentBattlesnake-v1_bb186570_0_2020-04-02_22-31-44ywxcmmz7/checkpoint_10/checkpoint-10 as /opt/ml/model/checkpoint\u001b[0m\n",
      "\u001b[34mSaved the checkpoint file /opt/ml/output/intermediate/training/PPO_MultiAgentBattlesnake-v1_bb186570_0_2020-04-02_22-31-44ywxcmmz7/checkpoint_10/checkpoint-10.tune_metadata as /opt/ml/model/checkpoint.tune_metadata\u001b[0m\n",
      "\u001b[34m2020-04-02 22:50:45,356#011INFO trainer.py:420 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\u001b[0m\n",
      "\u001b[34m2020-04-02 22:50:45,362#011INFO trainer.py:580 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=27681)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=27681)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=27681)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=27681)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=27681)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=27681)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=27681)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=27681)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=27681)#033[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=27681)#033[0m   obj = yaml.load(type_)\u001b[0m\n",
      "\u001b[34m2020-04-02 22:51:16,702#011INFO trainable.py:178 -- _setup took 31.341 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\u001b[0m\n",
      "\u001b[34m2020-04-02 22:51:18,554#011WARNING trainable.py:210 -- Getting current IP.\u001b[0m\n",
      "\u001b[34m2020-04-02 22:51:18,554#011INFO trainable.py:416 -- Restored on 10.0.156.121 from checkpoint: /opt/ml/model/checkpoint\u001b[0m\n",
      "\u001b[34m2020-04-02 22:51:18,554#011INFO trainable.py:423 -- Current state after restoring: {'_iteration': 10, '_timesteps_total': 371632, '_time_total': 1089.358297586441, '_episodes_total': 39188}\u001b[0m\n",
      "\u001b[34mSaved TensorFlow serving model!\n",
      "\u001b[0m\n",
      "\u001b[34m2020-04-02 22:51:24,035 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-02 22:51:54 Uploading - Uploading generated training model\n",
      "2020-04-02 22:51:54 Completed - Training job completed\n",
      "Training seconds: 1288\n",
      "Billable seconds: 1288\n",
      "Training job: battlesnake-rllib-ppo-2020-04-02-22-28-43-744\n",
      "CPU times: user 3.12 s, sys: 153 ms, total: 3.27 s\n",
      "Wall time: 23min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define and execute our training job\n",
    "# Adjust hyperparameters and train_instance_count accordingly\n",
    "\n",
    "metric_definitions = RLEstimator.default_metric_definitions(RLToolkit.RAY)\n",
    "    \n",
    "estimator = RLEstimator(entry_point=\"train-mabs.py\",\n",
    "                        source_dir='src',\n",
    "                        dependencies=[\"common/sagemaker_rl\", \"common/battlesnake_gym\", \"checkpoints\"],\n",
    "                        image_name=image_name,\n",
    "                        role=role,\n",
    "                        train_instance_type=instance_type,\n",
    "                        train_instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        base_job_name=job_name_prefix,\n",
    "                        metric_definitions=metric_definitions,\n",
    "                        hyperparameters={\n",
    "                            # See train-mabs.py to add additional hyperparameters\n",
    "                            # Also see ray_launcher.py for the rl.training.* hyperparameters\n",
    "                            #\n",
    "                            # number of training iterations\n",
    "                            \"num_iters\": 10,\n",
    "                            # number of snakes in the gym\n",
    "                            \"num_agents\": 5,\n",
    "                            # dimension of the gym. changing this could require changes to CNN kernels\n",
    "                            # in cnn_ft.py\n",
    "                            \"map_height\": 15,\n",
    "                            \n",
    "                            # Methods of representing the game state options: [\"flat-num\", \"bordered-num\",\n",
    "                            # \"max-bordered-num\", \"flat-51s\", \"bordered-51s\", \"max-bordered-51s\"]\n",
    "                            \"observation_type\": \"flat-51s\"\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "estimator.fit()\n",
    "\n",
    "job_name = estimator.latest_training_job.job_name\n",
    "print(\"Training job: %s\" % job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-412868550678/battlesnake-rllib-ppo-2020-04-02-21-35-26-268/output/model.tar.gz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where is the model stored in S3?\n",
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "#model_data = \"s3://sagemaker-us-west-2-412868550678/battlesnake-rllib-ppo-2020-03-30-20-06-31-079/output/model.tar.gz\"\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data=estimator.model_data,\n",
    "              role=role,\n",
    "              entry_point=\"inference.py\",\n",
    "              source_dir='inference',\n",
    "              framework_version='2.1.0',\n",
    "             )\n",
    "\n",
    "if local_mode:\n",
    "    inf_instance_type = 'local'\n",
    "else:\n",
    "    inf_instance_type = \"ml.t2.medium\"\n",
    "\n",
    "# Deploy an inference endpoint\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=inf_instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw inference results:\n",
      "   action_logp :  [0.0]\n",
      "   action_prob :  [1.0]\n",
      "   actions :  [0]\n",
      "   behaviour_logits :  [[0.0550115407, -0.031956654, -0.0453675911, 0.0185272116]]\n",
      "   heuristisc_action :  0\n",
      "   vf_preds :  [-0.753036618]\n",
      "\n",
      "Our model predicts that the next action to take is: action 0\n",
      "\n",
      "Inference took 706.75 ms\n"
     ]
    }
   ],
   "source": [
    "# Spoof an observation from a Battlesnake environment, and get the predicted action from the model\n",
    "#\n",
    "# This example is using single observation for a 5-agent environment with an 11x11 map\n",
    "# The last axis is 12 because the current MultiAgentEnv is concatenating 2 frames\n",
    "#   5 agent maps + 1 food map = 6 maps total    6 maps * 2 frames = 12\n",
    "#\n",
    "# Note: this prediction is for the first policy in the environment \"policy_0\"\n",
    "#   We need to fix this to export the 'best' policy, all policies, etc.\n",
    "#   Also - the agent's policy # and position within the observation *does* currently matter.\n",
    "#   For example, if we export policy_4 for inference, we need to ensure that the agent's current\n",
    "#   snake representation (during inference) is located within index 4 of the observations (food is index 0)\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "health_dict = {0: 50, 1: 50}\n",
    "json = {\"turn\": 4,\n",
    "        \"board\": {\n",
    "                \"height\": 15,\n",
    "                \"width\": 15,\n",
    "                \"food\": [],\n",
    "                \"snakes\": []\n",
    "                },\n",
    "            \"you\": {\n",
    "                \"id\": \"snake-id-string\",\n",
    "                \"name\": \"Sneky Snek\",\n",
    "                \"health\": 90,\n",
    "                \"body\": [{\"x\": 1, \"y\": 3}]\n",
    "                }\n",
    "            }\n",
    "\n",
    "fake_obs = np.zeros(shape=(1,11,11,12), dtype=np.float32).tolist()\n",
    "\n",
    "test_data = {\"inputs\": { 'observations': fake_obs,\n",
    "                        'prev_action': -1,\n",
    "                        'is_training': False,\n",
    "                        'prev_reward': -1,\n",
    "                        'seq_lens': -1\n",
    "                       },\n",
    "             \"all_health\": health_dict,\n",
    "             \"json\": json\n",
    "            }\n",
    "before = time()\n",
    "result = predictor.predict(test_data)\n",
    "elapsed = time() - before\n",
    "\n",
    "print(\"Raw inference results:\")\n",
    "for key in sorted(result['outputs'].keys()):\n",
    "    print(\"  \", key, \": \", result['outputs'][key])\n",
    "\n",
    "print()\n",
    "print(\"Our model predicts that the next action to take is: action\", result['outputs']['actions'][0])\n",
    "print()\n",
    "print(\"Inference took %.2f ms\" % (elapsed*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run to delete the endpoint\n",
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
